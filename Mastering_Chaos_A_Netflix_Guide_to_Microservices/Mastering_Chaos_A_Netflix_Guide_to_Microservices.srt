1
00:00:00,000 --> 00:00:03,940
샌프란시스코 QCon, 2017년 2월 22일에 녹화 되었습니다. 
[자막: 정윤진, yjeong@pivotal.io]

2
00:00:04,280 --> 00:00:06,280
좋아요, 와우!  꽉 찼네요 :-)

3
00:00:07,320 --> 00:00:09,320
바로 시작 할께요

4
00:00:10,000 --> 00:00:12,640
약 15년쯤 전에, 저의 양어머님께서는

5
00:00:12,820 --> 00:00:15,180
세션의 시작에 이런 이야기를 해서 좀 그렇긴 하지만,

6
00:00:15,180 --> 00:00:16,420
병이 드셨습니다.

7
00:00:16,660 --> 00:00:18,660
어머니는 몸 전체에서 고통을 느끼셨고

8
00:00:19,160 --> 00:00:21,900
몸이 약해지고, 혼자 서 있기도 힘들어 하셨으며

9
00:00:22,180 --> 00:00:26,740
어머니가 병원에 입원 하실 즈음에는 팔과 다리에 마비 증상도 있었습니다.

10
00:00:27,120 --> 00:00:30,540
그건 어머니에게도 저희 가족에게도 굉장히 무서운 경험이었습니다.

11
00:00:31,960 --> 00:00:34,700
어머니가 걸린 병은 귈랑 바레 증후군 이었습니다. 
[바이러스로 인한 다발성 신경염]

12
00:00:35,100 --> 00:00:37,360
혹시 이 병에 대해서 들어 본 분 계신가요? 그냥 궁금해서요

13
00:00:37,360 --> 00:00:38,620
와, 생각보다 많네요

14
00:00:38,620 --> 00:00:39,500
좋네요.

15
00:00:40,220 --> 00:00:43,080
아, 좋은건 아니죠. 이런 경험을 하지 않으셨기를 바랍니다.

16
00:00:43,800 --> 00:00:46,900
이 질병은 자가 면역 질환인데, 굉장히 흥미롭습니다.

17
00:00:47,440 --> 00:00:52,360
이 병은 다른 자가 면역 질환 처럼 어떤 외부 요인에 의해 발병하게 되는데요

18
00:00:52,820 --> 00:00:57,980
증상의 흥미로운 점은 항체가 신경 세포의 축색 돌기에 있는 피막을 공격한다는 것입니다,

19
00:00:58,080 --> 00:01:01,260
신경 세포에서 길게 뻗어 있는 이 부분을 공격하는 거죠

20
00:01:01,980 --> 00:01:06,420
공격은 축색 돌기를 침식시켜 신경망에 흐르는 신호가 결국 잘 전달되지 않게 됩니다.

21
00:01:06,860 --> 00:01:13,160
질병의 증상의 원인은 꽤 논리적이고 분명해서 이해가 가능합니다.

22
00:01:14,660 --> 00:01:17,260
좋은 소식은, 이 질병은 치료할 수 있다는 것입니다.

23
00:01:17,340 --> 00:01:21,140
혈장 분리 반출술을 사용해 피를 몸 밖으로 순환 시켜 필터를 통과한 혈액을 다시 주입하거나,

24
00:01:21,140 --> 00:01:22,460
항체 요법을 사용하는 것이죠.

25
00:01:22,500 --> 00:01:25,620
이런 치료들을 통해 어머니, 프랜시스는 성공적으로 병을 치료할 수 있었습니다.

26
00:01:26,760 --> 00:01:30,540
또 하나 흥미로운 점은, 이런 질병 이후 어머니의 반응이었습니다

27
00:01:30,860 --> 00:01:33,480
어머니는 이 병을 앓고 난 이후 건강에 더 신경을 쓰기 시작했고

28
00:01:33,800 --> 00:01:36,760
전보다 더 올바른 음식을 섭취하고, 운동을 조금 더 하시고

29
00:01:37,180 --> 00:01:41,280
예를 들면 기공(氣功)과 태극권을 수련을 시작하셨고

30
00:01:41,420 --> 00:01:45,860
그리고 다시는 이런 질병을 겪지 않도록 조심하셨습니다.

31
00:01:47,420 --> 00:01:51,000
이 사건을 통해 제가 배운 점이라면,

32
00:01:51,500 --> 00:01:54,040
인간의 몸이 얼마나 놀라운가 하는 것과

33
00:01:54,260 --> 00:01:58,880
사람이 숨쉬는 것처럼 단순하고 당연해 보이는 세상과 교감하는 것들이

34
00:01:58,880 --> 00:02:01,000
실제로 살펴보면 기적에 까가운 것들이라는 점 입니다.

35
00:02:01,100 --> 00:02:03,880
어떤 특정 부분에서는 엄청나게 용감한것 아닌가 할 수 있는데

36
00:02:03,900 --> 00:02:05,900
실제 세상에는 수많은 위험들이 도사리고 있고,

37
00:02:06,060 --> 00:02:09,960
예를 들면 많은 종류의 알러지나, 박테리아 감염, 그 외에도 다양한 요인들이 있습니다.

38
00:02:09,980 --> 00:02:11,980
이런 것들은 우리의 몸에 나쁜 영향을 미칠 수 있죠.

39
00:02:13,020 --> 00:02:17,980
아마도 여러분은 제가 왜 이런 질병과 관련된 이야기를 하는지 궁금하실 겁니다.

40
00:02:19,000 --> 00:02:22,360
우리의 몸이 용감하게 세상 속에서 숨쉬는 것처럼

41
00:02:22,360 --> 00:02:25,440
마이크로 서비스에서 트래픽을 받는것 역시 기적처럼 동작한다는 것입니다.

42
00:02:25,720 --> 00:02:27,720
여러분은 갑자기 폭증하는 트래픽이나,

43
00:02:27,720 --> 00:02:29,680
DDoS 공격을 처리하고,

44
00:02:29,840 --> 00:02:32,340
서비스 구동 환경에 변화를 반영해야 할 것입니다.

45
00:02:32,360 --> 00:02:36,700
이 모두는 잘못하면 전체 서비스가 다운 되어 고객들의 서비스 사용이 불가할 수 있습니다.

46
00:02:37,360 --> 00:02:39,920
이게 바로 우리가 오늘 여기에 모여 이야기 할 주제인,

47
00:02:40,040 --> 00:02:42,820
엄청난 장점을 제공하는 마이크로 서비스를 이야기 할겁니다

48
00:02:42,880 --> 00:02:47,580
그리고 넷플릭스가 마이크로 서비스를 구현하면서 겪었던 어려운점, 힘든점에 대해서도 이야기 할 겁니다.

49
00:02:47,720 --> 00:02:52,900
지난 7년 동안, 저희는 굉장히 다양한 문제들과 싸워 왔습니다

50
00:02:54,060 --> 00:02:57,020
오늘 세션은 일단 저에 대한 간단한 소개와

51
00:02:57,640 --> 00:03:00,740
모든 분들의 공통적 이해를 위한 약간의 설명,

52
00:03:00,860 --> 00:03:05,040
예를 들면 마이크로 서비스에서 자주 사용되는 용어들 같은것이죠.

53
00:03:05,400 --> 00:03:10,840
그리고 저희 넷플릭스가 겪었던 도전과 그에 대한 해법

54
00:03:11,180 --> 00:03:13,180
마지막으로는

55
00:03:13,220 --> 00:03:18,060
조직의 구조와 아키텍처가 어떻게 서로 연관이 있는지에 대해서도 이야기 할 겁니다.

56
00:03:19,340 --> 00:03:22,220
제 소개를 하자면, 안녕하세요, 저는 조쉬 에반스 입니다

57
00:03:22,460 --> 00:03:24,940
저는 넷플릭스에서 일을 시작한게... 어...

58
00:03:24,940 --> 00:03:26,540
물론 그전에도 직장은 있었지만,

59
00:03:26,540 --> 00:03:28,480
아마도 제일 의미 있는 경력이구요

60
00:03:28,540 --> 00:03:33,740
1999년 넷플릭스가 DVD 구독 서비스를 시작하기 한달전 쯤에 입사했구요

61
00:03:34,060 --> 00:03:37,240
e-커머스 부분에서 엔지니어링도 하고 매니저도 하고

62
00:03:37,400 --> 00:03:44,120
기존의 e-커머스 사업과 유사한 기존의 DVD 사업 모델을 스트리밍 사업으로의 변화에 참여 했습니다.

63
00:03:45,440 --> 00:03:49,320
2009년에는 스트리밍의 핵심 부분을 관리하는 팀의 디렉터로 옮겼는데,

64
00:03:49,340 --> 00:03:51,340
오늘날 "플레이백"서비스로 불리는 부분이구요

65
00:03:51,460 --> 00:03:56,980
이 팀에서는 DRM, Manifest 딜리버리, 그리고 장치에서 유입되는 정보를 녹화(처리)하는 일을 합니다.

66
00:03:57,400 --> 00:04:01,920
넷플릭스 서비스가 글로벌로 진출할때 이 팀을 리드했는데,

67
00:04:01,940 --> 00:04:04,600
세상의 모든 장치에 넷플릭스를 올리는 일이죠

68
00:04:04,720 --> 00:04:08,400
그리고 사이드 프로젝트로 데이터센터를 클라우드로 옮기는 일도 했습니다.

69
00:04:08,420 --> 00:04:10,880
좀 재미있는 일이었어요

70
00:04:11,900 --> 00:04:15,940
그리고 최근 3년 동안은 "오퍼레이션 엔지니어링" 팀의 매니저였고

71
00:04:16,020 --> 00:04:18,100
운영의 고도화를 위해 집중하는 팀이었습니다.

72
00:04:18,100 --> 00:04:19,940
속도를 개선하기 위한 엔지니어링,

73
00:04:19,960 --> 00:04:23,060
모니터링과 알람, 딜리버리,

74
00:04:23,220 --> 00:04:26,400
카오스 관련된 엔지니어링과 다양한 기능을 하는 수많은 도구들

75
00:04:26,400 --> 00:04:31,200
넷플릭스 엔지니어들이 "클라우드"에서 성공적으로 서비스를 운영할 수 있도록 돕는 것이었죠.

76
00:04:31,800 --> 00:04:36,040
그런 날들을 지나 결국 한달 전에 넷플릭스를 그만두게 되었구요

77
00:04:36,080 --> 00:04:39,060
사실 오늘 저는 '아리아나 허핑턴' 에 대해 많은 생각을 합니다.

78
00:04:39,520 --> 00:04:42,960
생전 처음으로 모자랐던 수면을 보충하고,

79
00:04:43,080 --> 00:04:45,080
그냥 좀 쉬기도 하고

80
00:04:45,080 --> 00:04:46,900
가족과 즐거운 시간을 보내기도 하구요

81
00:04:46,940 --> 00:04:49,540
일과 삶의 균형이 어디쯤인지 찾는 중입니다.

82
00:04:49,540 --> 00:04:53,460
사실 지금은 "삶"쪽에 치중되어 있죠. 이전과는 다른 생활을 하고 있어서 좋습니다

83
00:04:54,740 --> 00:04:58,920
넷플릭스는 오늘날 등록제 인터넷 텔레비전의 선두 주자구요

84
00:04:59,140 --> 00:05:04,000
할리우드나 인디, 또는 지역의 컨텐츠를 계약해서 공급하기도 하고

85
00:05:04,200 --> 00:05:07,380
직접 만드는 오리지널 컨텐츠의 양도 굉장히 많아지고 있습니다.

86
00:05:07,600 --> 00:05:10,800
오늘날 약 8600만명의 가입자가 있구요

87
00:05:10,860 --> 00:05:13,160
이 숫자는 전세계 사용자 숫자고, 빠르게 증가하고 있습니다.

88
00:05:14,100 --> 00:05:16,960
오늘날 넷플릭스는 190여개 국가에서 서비스 중이며

89
00:05:16,960 --> 00:05:21,440
.자막, 사용자 인터페이스등이 10개 이상의 언어로 서비스되고 있습니다

90
00:05:22,620 --> 00:05:24,860
천여개에 이르는 장치에서 동작하구요

91
00:05:25,200 --> 00:05:29,300
그리고 모든 마이크로 서비스들은 AWS 위에서 동작 합니다.

92
00:05:31,440 --> 00:05:36,680
자 그럼 이제 마이크로 서비스가 무엇인지에 대해서부터 이야기 해 보죠

93
00:05:37,580 --> 00:05:41,980
제가 좋아하는 접근 방법은, "어떤게 마이크로 서비스가 아닌가" 를 먼저 보는 것입니다.

94
00:05:41,980 --> 00:05:46,600
2000년도 즈음에 넷플릭스가 웹 기반의 DVD 사업을 하던 시절

95
00:05:46,700 --> 00:05:51,140
사용자들은 큐에 원하는 DVD를 넣고, 우체통을 통해 주고 받을때죠

96
00:05:52,220 --> 00:05:55,360
이 당시 우리의 아키텍처는 간단했는데요

97
00:05:55,360 --> 00:05:57,200
하드웨어 기반의 로드 밸런서가 있구요

98
00:05:57,240 --> 00:06:02,340
사실 엄청나게 고가의 하드웨어를 사용한 리눅스 서버들이 있구요

99
00:06:02,880 --> 00:06:07,900
이 서버에는 아파치 톰캣이나 리버스 프락시 같은 것들을 사용한 일반적 구성이었고

100
00:06:08,160 --> 00:06:11,100
그리고 거기에는 한개의 애플리케이션이 있었는데, 자바 웹 이었죠

101
00:06:11,120 --> 00:06:14,640
고객이 접속해서 하는 모든것들을 제공하는 자바 애플리케이션이었죠

102
00:06:15,960 --> 00:06:19,760
이 자바 애플리케이션은 JDBC로 오라클 데이터베이스에 직접 연결 되어 있었구요

103
00:06:19,800 --> 00:06:24,080
그리고 데이터베이스 링크로 다른 오라클 데이터베이스와 연결되었습니다.

104
00:06:25,900 --> 00:06:31,120
이 구조의 첫번째 문제는 바로 자바 애플리케이션 코드 베이스가 "모놀리틱" 인 것이었습니다.

105
00:06:31,360 --> 00:06:38,320
매주 반복적으로 배포되는 애플리케이션의 코드 베이스에 모든 사람들이 한꺼번에 붙어서 작업을 해야 했죠

106
00:06:39,160 --> 00:06:43,120
이런 구조는 변경이 발생 할때마다 문제를 일으켰고,

107
00:06:43,240 --> 00:06:45,240
문제가 발생하면  분석이 엄청 어려웠습니다.

108
00:06:45,260 --> 00:06:49,200
천천히 증가하는 메모리 누수를 찾는데 일주일이 걸린적도 있습니다

109
00:06:49,340 --> 00:06:54,820
문제를 찾기위해 코드를 변경하고, 다시 구동하고  분석을 시도하고, 다시 변경하고 하는

110
00:06:55,000 --> 00:06:58,280
하나의 애플리케이션에 너무 많은 변경이 발생했기 때문에

111
00:06:58,300 --> 00:07:00,300
분석에 필요한 시간이 점점 늘어났습니다.

112
00:07:02,160 --> 00:07:06,560
데이터베이스는 더 심각한 모놀리틱 상태였습니다.

113
00:07:06,680 --> 00:07:12,880
이건 거대한 하드웨어에서 동작하는 거대한 하나의 오라클 데이터베이스 였는데, '스토어 데이터베이스' 라고 불렀습니다.

114
00:07:13,080 --> 00:07:15,720
이게 다운되면, 서비스 전체가 다운 이었습니다.

115
00:07:15,960 --> 00:07:19,300
그리고 매년 휴가철의 피크 트래픽이 유입 되면

116
00:07:19,380 --> 00:07:24,680
부하로 인한 문제를 방지하기 위해 항상 더 좋은 하드웨어를 찾아 다녔습니다.

117
00:07:26,580 --> 00:07:31,220
엔지니어링 측면에서 가장 심각한 문제는

118
00:07:31,220 --> 00:07:35,160
모든게 서로 너무 깊게 연결되어 있기 때문에 변경에 속도가 나지 않는다는 것이었습니다.

119
00:07:35,940 --> 00:07:41,040
데이터베이스에 직접 연결하고, 테이블 스키마에 깊은 의존성을 가지는 애플리케이션들은

120
00:07:41,080 --> 00:07:46,100
테이블에 컬럼을 추가하는 간단한 변경도 거대한 크로스팀 프로젝트로 만들어 버렸습니다.

121
00:07:46,700 --> 00:07:50,300
바로 이런 모델이 오늘날 만들면 안되는 서비스의 전형적인 모습입니다.

122
00:07:50,520 --> 00:07:55,260
하지만 이런 모델은 90년대 후반부터 2000년대초반까지 매우 일반적인 것이었습니다.

123
00:07:56,160 --> 00:07:58,160
그럼 마이크로 서비스는 무얼까요?

124
00:07:58,240 --> 00:08:03,620
여기 계신분 중 혹시 마이크로 서비스에 대한 정의를 말씀해 주실 분 계신가요?

125
00:08:05,040 --> 00:08:07,880
용감한 영혼 안계신가요? // 아 저기 계시네요

126
00:08:08,100 --> 00:08:09,720
마이크로 서비스가 뭔가요?

127
00:08:10,080 --> 00:08:12,780
[뭐라고 뭐라고 답변]

128
00:08:12,780 --> 00:08:14,100
다시 말해줄래요?

129
00:08:16,380 --> 00:08:19,240
Context bound 와 데이터 오너쉽, 마음에 드는 답변이네요

130
00:08:20,860 --> 00:08:23,860
마틴 파울러의 마이크로 서비스 정의를 인용할께요

131
00:08:23,860 --> 00:08:25,400
중요한 부분이죠

132
00:08:25,440 --> 00:08:27,440
제가 읽어 드릴께요

133
00:08:27,860 --> 00:08:33,680
마이크로 서비스 아키텍처 스타일은 작은 서비스의 집합으로 하나의 애플리케이션을 구현 하는 것이며

134
00:08:33,680 --> 00:08:36,180
각각의 작은 서비스들은 자신만의 독립적인 프로세스를 가지고 있고

135
00:08:36,180 --> 00:08:40,220
가벼운 구조를 가지는데, HTTP 기반의 API 를 사용해 서로 연동한다.

136
00:08:40,440 --> 00:08:45,440
이런 정의에 대해서는 아마 대부분 알고 있고, 또 기술적으로 맞는 이야기지만

137
00:08:45,440 --> 00:08:49,760
실제로 마이크로 서비스를 구현 할때 도움이 되는 이야기는 아닌것 같습니다.

138
00:08:50,880 --> 00:08:58,360
제 개인적인 느낌의 마이크로 서비스는 이전 2000년대 사용했던 모놀리틱 문제의 해결 아닐까 합니다.

139
00:08:59,160 --> 00:09:04,220
위험을 잘게 쪼개어 내는것이 아마도 마이크로 서비스 전환의 가장 큰 부분이자 동기인것 같구요

140
00:09:04,340 --> 00:09:11,640
모듈화 하고, 서비스에 필요한 데이터를 캡슐화 함으로서 전체 서비스를 하나의 덩어리로 고려하지 않아도 됩니다.

141
00:09:12,540 --> 00:09:17,880
수평적 확장을 고려하고 있다면 아마도 올바른 접근일 것이구요

142
00:09:18,020 --> 00:09:25,060
거대한 워크로드를 거대한 시스템이 아니라 여러개의 작은 부분으로 분리해서 처리하는 분산의 개념이 필요 합니다

143
00:09:26,040 --> 00:09:30,260
사실 개인적으로 생각하기에 말씀 드린 것들이 제대로 동작하려면

144
00:09:30,600 --> 00:09:33,780
탄력성을 가진 가상화 기반 환경이 반드시 필요했습니다.

145
00:09:33,780 --> 00:09:38,940
만약 이런 가상화 된 환경이 없었다면, 마이크로 서비스를 운영하는 것은 아주아주아주 힘든일이었을 겁니다.

146
00:09:39,220 --> 00:09:42,560
운영에 필요한 것들은 가능하면 최대한 자동화를 해야 하며

147
00:09:42,660 --> 00:09:48,100
필요에 따라 리소스를 만들고 제거가 가능한건 마이크로 서비스를 구현할때 매우매우매우 큰 장점이었습니다.

148
00:09:49,100 --> 00:09:52,880
다시 사람의 장기로 이 개념들을 비유해 보면,

149
00:09:53,040 --> 00:09:56,320
마이크로 서비스를 인체의 여러 장기로 이해할 수 있습니다.

150
00:09:56,900 --> 00:10:00,600
각각의 장기가 모여 여러분의 몸을 형성하는 것과 같이 말입니다.

151
00:10:01,180 --> 00:10:05,120
이런 것들이 어떻게 매핑될 수 있는지 잠깐 넷플릭스 아키텍처를 살펴 보겠습니다.

152
00:10:06,180 --> 00:10:10,860
ELB 뒤에는 동적인 라우팅을 수행하는 Zuul 로 구성된 프락시 계층이 있습니다.

153
00:10:11,820 --> 00:10:18,880
또한 NCCP라 불리는 레거시 계층이 있는데, 이는 오래된 옛날 장치를 지원하고, 기본적인 영화 재생 기능을 제공합니다.

154
00:10:19,760 --> 00:10:23,060
그리고 넷플릭스 API 가 API 게이트웨어를 통해 제공 되는데

155
00:10:23,160 --> 00:10:26,400
현재 넷플릭스 아키텍처의 핵심중의 하나로서

156
00:10:26,520 --> 00:10:30,540
고객이 발생시키는 요청에 대한 응답을 처리하기 위해 다른 많은 서비스들과 통신 합니다.

157
00:10:31,620 --> 00:10:35,980
지금 보시는 박스 안의 서비스들을 우리는 "엣지" 서비스로 부르는데,

158
00:10:36,160 --> 00:10:41,320
여기에 도식화 되지 않은  DRM 같은 서비스도 엣지 서비스 군에 속합니다.

159
00:10:41,940 --> 00:10:44,420
그리고 오른쪽에 보시면

160
00:10:44,480 --> 00:10:50,120
이쪽에는 각종 기능을 하는 서비스들이 미들 티어와 플랫폼이 합쳐진 형태로 구성되어 있습니다.

161
00:10:51,080 --> 00:10:56,160
여기에 속한 것들이 어떤 서비스들이 있는지 이해를 돕기 위해 좀 더 깊이 살펴 보겠습니다.

162
00:10:56,900 --> 00:11:04,120
여기엔 A/B 테스트 인프라가 있고, 고객이 연결될 테스트용 A, B 서비스가 동작합니다.

163
00:11:04,460 --> 00:11:10,380
서브스크립션 서비스는 넷플릭스 고객에 대한 거의 모든 정보를 가지고 있습니다.

164
00:11:10,380 --> 00:11:12,200
추천시스템은,

165
00:11:12,340 --> 00:11:18,720
각 고객에게 맞는 적절한 영화를 제안하기 위한 기능을 수행하고,

166
00:11:18,780 --> 00:11:22,940
플랫폼 서비스들은 보다 기초적인 기능을 제공하기 위해 존재 합니다.

167
00:11:23,080 --> 00:11:26,420
라우팅은 마이크로 서비스들이 서로를 찾아 연결하는데 도움을 주고

168
00:11:26,540 --> 00:11:28,540
동적 설정 변경을 지원 하거나,

169
00:11:28,540 --> 00:11:30,080
암호화 관련 작업들,

170
00:11:30,160 --> 00:11:32,660
그리고 데이터를 영구 보존하기 위한 서비스들이 있습니다.

171
00:11:33,100 --> 00:11:36,900
이것들은 일종의 오브젝트로서, 전체 시스템의 일부로 동작합니다.

172
00:11:37,760 --> 00:11:41,660
또한 저는, 마이크로 서비스 역시 일종의 추상화라고 생각합니다.

173
00:11:42,220 --> 00:11:45,160
일반적으로 우린 마이크로 서비스를 매우 단순하게 이해하려는 경향이 있습니다.

174
00:11:45,220 --> 00:11:48,400
"음, 여기 수평적으로 잘 확장 되는 마이크로 서비스가 있으니,"

175
00:11:48,400 --> 00:11:50,040
"다른 서비스들이 별 문제 없이 호출해서 접근할 수 있겠지"

176
00:11:50,120 --> 00:11:53,420
간단한것 같지만 실제로 이건 절대로 이렇게 간단한 것이 아닙니다.

177
00:11:54,020 --> 00:11:55,560
또, 언젠가는 데이터가 필요하게 됩니다.

178
00:11:55,800 --> 00:11:59,920
여러분의 서비스는 다양한 이유로 데이터를 사용하게 됩니다.

179
00:11:59,920 --> 00:12:02,660
예를 들면 가입자에 대한 정보가 필요하거나, 추천 정보와 같은 것들이죠

180
00:12:02,660 --> 00:12:05,060
그런데 데이터는 대부분 '영구 보존 레이어' 에 위치 합니다.

181
00:12:05,820 --> 00:12:11,800
음, 이런 편의를 우선시하는 방법은 넷플릭스가 좋아하는 접근인데요

182
00:12:11,900 --> 00:12:14,680
넷플릭스에서 정말 많이 사용된 방법인데,

183
00:12:14,940 --> 00:12:18,840
자바 기반의 클라이언트 라이브러리를 제공 하구요

184
00:12:19,000 --> 00:12:24,300
이런 자바 라이브러리는 데이터 접근과 같은 작업을 위해 제공 되었습니다.

185
00:12:25,100 --> 00:12:29,220
그리고 어떤 시점에 분명, 여러분은 캐시가 필요하게 될 겁니다.

186
00:12:29,280 --> 00:12:32,960
왜냐 하면 서비스와 데이터베이스 만으로는 성능이 충분하지 않을 수 있기 때문인데요

187
00:12:33,220 --> 00:12:35,620
그래서 캐시 접근을 위한 클라이언트도 필요하게 됩니다.

188
00:12:36,500 --> 00:12:39,240
이제 여러분은 "조율"에 대해 고려해야 합니다

189
00:12:39,240 --> 00:12:41,140
캐시를 먼저 살펴 보구요

190
00:12:41,140 --> 00:12:42,640
만약 데이터가 거기에 없다면

191
00:12:42,700 --> 00:12:45,100
서비스는 다시 데이터베이스를 호출합니다.

192
00:12:45,540 --> 00:12:52,800
요청에 대한 응답 데이터를 주고 나면 다음번의 동일한 데이터 요청을 더 빨리 처리하기 위해 캐시에 저장하게 될 겁니다.

193
00:12:53,680 --> 00:12:59,220
이렇게 구성된 클라이언트 라이브러리는 각각의 마이크로 서비스에 임베드 됩니다.

194
00:12:59,680 --> 00:13:02,180
이 클라이언트 라이브러리의 관점에서 살펴 보자면

195
00:13:02,500 --> 00:13:09,180
이 구조를 이루는 전체 기술과 복잡한 설정의 조합이 바로 마이크로 서비스 입니다.

196
00:13:09,360 --> 00:13:13,860
이건 말로 하기 쉬운 "Statless" 같이 이론적으로 간단한 무엇이 아니라

197
00:13:13,920 --> 00:13:17,400
실제로는 꽤나 복잡한 구조를 가지고 있는 것이죠

198
00:13:18,400 --> 00:13:22,000
여기까지가 마이크로 서비스에 대한 공감대를 만드는 내용이었구요

199
00:13:22,320 --> 00:13:25,980
이제 우리가 지난 7년동안 받았던 챌린지들을 살펴 보겠습니다.

200
00:13:26,160 --> 00:13:28,780
그리고 해법과 해법의 철학에 대해서도 이야기 해 보지요

201
00:13:29,280 --> 00:13:33,360
[물 마시는 중]

202
00:13:33,800 --> 00:13:36,040
저는 정크 푸드를 좋아하는데요

203
00:13:36,180 --> 00:13:38,160
그리고 저는 지금 보시는 이미지를 아주 좋아하는데요

204
00:13:38,240 --> 00:13:44,900
경험상 마이크로 서비스에 관한 문제와 문제의 해결은 우리의 버릇과 관련이 깊기 때문입니다.

205
00:13:45,080 --> 00:13:48,660
대부분의 사례의 목적은 우리가 채소를 더 많이 먹도록 하는 것이었습니다.

206
00:13:49,120 --> 00:13:55,060
음, 다음 4가지 기준을 바탕으로 사례들을 깊이 살펴 볼건데요

207
00:13:55,140 --> 00:13:59,160
4가지는 문제 접근의 기본 방향이었습니다.

208
00:13:59,160 --> 00:14:00,900
의존성

209
00:14:00,900 --> 00:14:02,420
확장

210
00:14:03,380 --> 00:14:05,560
다양성, 즉 다양한 아키텍처의 수용

211
00:14:06,020 --> 00:14:07,700
변경을 어떻게 처리할 것인지

212
00:14:09,160 --> 00:14:11,160
의존성부터 시작해 봅시다

213
00:14:11,360 --> 00:14:15,020
의존성과 관련된 네가지 사례에 대해 살펴 볼겁니다.

214
00:14:16,700 --> 00:14:21,220
인트라-서비스 요청들, 이건 마이크로 서비스  A가 마이크로 서비스 B를 호출하고,

215
00:14:21,220 --> 00:14:23,480
이는 보다 더 큰 요청을 처리하기 위해 필요 합니다.

216
00:14:24,160 --> 00:14:28,460
시작할때 드렸던 이야기에서의 신경망 처럼

217
00:14:28,880 --> 00:14:30,880
동작하는 와중에는 모든게 대단 합니다.

218
00:14:31,060 --> 00:14:34,360
하지만 거대한 계곡을 건너야 하는 경우엔 문제에 직면하게 됩니다.

219
00:14:34,860 --> 00:14:38,160
서비스가 다른 서비스를 호출할 때

220
00:14:38,380 --> 00:14:43,080
프로세스와 서버를 벗어나는 것 자체가 사실 큰 위험입니다.

221
00:14:43,500 --> 00:14:50,320
네트워크의 지연시간, 혼잡성, 하드웨어 오류, 트래픽으로 인한 라우팅 문제,

222
00:14:50,740 --> 00:14:53,360
또는 호출한 서비스가 정상적인 상태가 아닐 수도 있구요

223
00:14:53,360 --> 00:14:56,200
예를 들면 잘못된 배포나 논리적 버그 같은 문제들

224
00:14:56,240 --> 00:14:58,240
적절한 규모로 확장 되지 못했거나

225
00:14:58,360 --> 00:15:03,260
요청에 대한 응답이 느려지거나, 타임 아웃이 발생하거나 에러가 발생하게 됩니다.

226
00:15:05,060 --> 00:15:08,940
굉장히 많이 발생하는 장애 시나리오 중의 하나는

227
00:15:09,080 --> 00:15:12,040
이 시나리오에서 하나의 서비스에서

228
00:15:12,040 --> 00:15:13,560
장애가 발생하면,

229
00:15:13,560 --> 00:15:16,660
이 하나의 서비스 장애에 대해 잘못된 방어 구조를 가지고 있는 경우에는

230
00:15:16,700 --> 00:15:20,940
이 하나의 장애가 다른 서비스의 장애를 야기하는 연속 장애가 발생하고, 결과적으로 전체 서비스에 문제가 생깁니다.

231
00:15:21,420 --> 00:15:25,200
그리고 신께서는 이런 문제가 다른 리전으로 까지 전이 되는것은 잘 허용치 않기는 합니다만,

232
00:15:25,280 --> 00:15:31,040
이건 물론 여러분이 멀티 리전 전략을 사용하는 경우에는 그렇지만, 일단 문제가 발생한 지역에서 해결을 봐야 합니다.

233
00:15:32,760 --> 00:15:36,180
이런 문제를 방지하기 위해서 넷플릭스는 Hystrix 라는 도구를 만들었습니다.

234
00:15:36,380 --> 00:15:41,200
이 도구는 타임아웃이나 재시도 같은 동작을 구조적으로 다룰 수 있으며,

235
00:15:41,220 --> 00:15:43,520
그리고 fallback 이라고 불리는 컨셉을 가지고 있는데

236
00:15:43,620 --> 00:15:45,940
이건 만약 내가 서비스 B를 호출 할 수 없다면

237
00:15:45,940 --> 00:15:48,640
사전에 지정된 static 한 응답을 주는 등의 동작을 하는 것이죠

238
00:15:48,660 --> 00:15:52,660
이건 고객이 에러를 보게 하는 대신, 서비스가 계속 동작하는 것처럼 보이게 할 수 있습니다.

239
00:15:53,080 --> 00:15:59,460
그리고 Hystrix 가 제공하는 아주 큰 장점은 "고립된 스레드 풀"과 "서킷"에 대한 컨셉입니다.

240
00:15:59,780 --> 00:16:04,380
만약 서비스 B가 장애인 상황에서 계속 호출하는 것 보다는, 호출을 중지하는게 더 좋은 방법일 겁니다.

241
00:16:04,660 --> 00:16:08,700
장애로 처리하고, 지정된 fallback으로 응답하고, 서비스 B가 복구되길 기다립니다.

242
00:16:09,520 --> 00:16:14,040
Hystrix는 넷플릭스 안에서 매우 광범위하게 사용되고 있습니다.

243
00:16:14,740 --> 00:16:17,000
이제 매우 기본적인 질문을 해야 할 필요가 있는데요, 그것은 바로

244
00:16:17,040 --> 00:16:20,240
마이크로 서비스들을 올바르게 설정한 것 같고, Hystrix도 올바르게 설정을 완료 했다면,

245
00:16:20,300 --> 00:16:24,000
이런것들이 제대로 동작하는지 어떻게 알죠?

246
00:16:25,780 --> 00:16:28,940
의학 관련 이야기로 돌아가 보면, 가장 좋은 방법은

247
00:16:28,940 --> 00:16:30,560
바로 예방 접종 입니다.

248
00:16:30,640 --> 00:16:33,820
죽은 버전의 바이러스를  몸에 주사하는 것입니다.

249
00:16:34,060 --> 00:16:37,280
그러면 몸에 있는 항체가 살아있는 바이러스에 대한 항체를 만들죠

250
00:16:38,000 --> 00:16:42,100
비슷하게, 실패를 프로덕션에 주입하는 방법을 통해 장애에 대한 내성을 가질수 있습니다.

251
00:16:42,460 --> 00:16:47,020
이 '실패 주입'을 위해, 넷플릭스는 FIT 를 만들었습니다. 
[장애 주입 테스트 프레임워크]

252
00:16:48,160 --> 00:16:53,120
FIT는 장치나 어카운트에서 생성된 트랜젝션을 설정과 오버라이드해서 만들어진 '합성 트랜젝션'을 프로덕션에 주입할 수 있습니다.

253
00:16:53,820 --> 00:16:56,780
그리고 FIT로 서비스에 유입되는 합성 트랜젝션 또는 라이브 트래픽의 비율을 조정할 수 있습니다.

254
00:16:56,840 --> 00:17:02,560
모든게 정상 동작한다고 생각 되면, 라이브 트래픽의 비율을 늘려서 실제 부하 상태에서는 어떻게 동작하는지 확인할 수 있습니다.

255
00:17:04,180 --> 00:17:08,640
여기서는 어떤 형태의 테스트건 모두 수행할 수 있어야 합니다

256
00:17:08,640 --> 00:17:15,100
직접 호출하건, 직접 호출하지 않건간에 테스트 하려는 요청을 올바르게 설정 하면

257
00:17:15,420 --> 00:17:21,240
프로덕션에서의 서비스 다운 없이 서비스에 발생하는 문제를 모의할 수 있게 됩니다.

258
00:17:23,020 --> 00:17:26,520
지금 보는 애니메이션은 포인트 - 포인트 연결을 잘 보여줍니다.

259
00:17:27,100 --> 00:17:30,000
100개의 마이크로 서비스가 동작하고 있다고 상상해 보세요

260
00:17:30,140 --> 00:17:35,100
그리고 이 서비스들은 하나 또는 여러개의 서비스에 의존성을 가지고 있습니다.

261
00:17:35,100 --> 00:17:37,080
여기서 매우 큰 도전이 발생하는데

262
00:17:37,220 --> 00:17:40,520
서비스의 테스트와 범위를 어떻게 제한해야

263
00:17:40,520 --> 00:17:45,740
수백개의 서비스가 서로 통신하는걸 전부 살펴보지 않고도 테스트를 수행할 수 있을까요

264
00:17:47,440 --> 00:17:51,020
이건 가용성 측면에서 매우 중요합니다.

265
00:17:51,320 --> 00:17:55,800
여러분의 서비스가 단 10개의 서비스로 이루어졌다고 합시다

266
00:17:56,380 --> 00:18:03,280
그리고 각각의 서비스는 99.99%의 가용성으로 동작하는데, 이건 1년에 53분의 다운만 허용하는 수치 입니다.

267
00:18:04,380 --> 00:18:11,300
가용성 관련 숫자로는 대단한것 같지만, 일년간의 수치를 모두 다 합치게 되면

268
00:18:12,240 --> 00:18:16,880
전체 서비스는 99.9의 가용성을 가지게 됩니다.

269
00:18:17,540 --> 00:18:21,800
이건 1년에 8-9시간의 장애에 해당하며, 99.99와는 야구장만한 차이가 나는 것이죠

270
00:18:23,140 --> 00:18:25,140
이런 개념을 바탕으로

271
00:18:25,400 --> 00:18:28,520
넷플릭스는 먼저 '치명적인 마이크로 서비스들'을 정의했는데

272
00:18:28,520 --> 00:18:32,560
이는 아주 기본이 되는 서비스의 동작을 위해 필수적으로 필요한 것들 입니다.

273
00:18:32,840 --> 00:18:34,840
고객이 애플리케이션을 구동하고

274
00:18:35,040 --> 00:18:37,040
어떤 영화를 보아야 할지 브라우징을 하고

275
00:18:37,080 --> 00:18:39,300
예를 들면 가장 유명한 영화 리스트에서

276
00:18:39,360 --> 00:18:41,360
플레이버튼을 누르면 재생이 되어야 하는 것이죠

277
00:18:42,280 --> 00:18:46,440
이런 접근 방법을 통해 서비스에 치명적인 마이크로 서비스들을 구분해 내고

278
00:18:46,440 --> 00:18:47,760
그룹화 해서

279
00:18:48,060 --> 00:18:55,580
FIT 레시피에서 이 그룹외의 나머지 서비스를 배제한 레시피를 만들어 테스트의 범위를 제한 합니다.

280
00:18:55,980 --> 00:19:00,440
이런 분류 방법을 사용해서 프로덕션에서 매우 짧은 시간동안 테스트를 수행하는 방법으로

281
00:19:00,680 --> 00:19:06,700
모든 의존성 있는 서비스들이 동작하지 않는 상태에서도 대상 서비스의 동작 여부를 확인할 수 있습니다.

282
00:19:07,220 --> 00:19:11,740
이 방법은 모든 포인트 - 포인트 연동을 확인하지 않아도 되는 단순함을 제공하며

283
00:19:11,820 --> 00:19:15,780
넷플릭스가 치명적인 에러를 찾아내는데 매우 큰 도움을 주었습니다.

284
00:19:17,440 --> 00:19:19,760
이제 클라이언트 라이브러리에 대해 이야기 해 봅시다.

285
00:19:19,880 --> 00:19:21,880
주제를 완전히 바꿔 봅시다.

286
00:19:22,160 --> 00:19:27,220
처음 클라우드로 서비스를 이전하면서, 클라이언트 라이브러리에 대한 뜨거운 논쟁이 있었습니다.

287
00:19:27,440 --> 00:19:32,080
야후에서 일했던 뛰어난 분들이 넷플릭스로 왔는데

288
00:19:32,100 --> 00:19:35,780
이분들은 '베어 본 REST' 라 불리는 모델의 강력한 지지자들이 많았습니다.

289
00:19:35,840 --> 00:19:41,380
어떠한 클라이언트 라이브러리도 사용하지 않고 모든 요청을 베어-본으로 처리하는 것이죠.

290
00:19:41,600 --> 00:19:45,880
동시에 클라이언트 라이브러리를 만들어야 한다는 주장 역시 강력했습니다.

291
00:19:46,520 --> 00:19:49,680
만약 공통 로직과 공통 접근 패턴을 가지고 있는 상태에서,

292
00:19:49,720 --> 00:19:53,400
내 서비스에 20-30개의 서비스 의존성이 있는 상태라면

293
00:19:53,580 --> 00:19:59,380
이 모든 팀들이 내 서비스 접근을 위해 반복적으로 동일하거나 거의 동일한 코드를 작성하도록 하는것이 맞는지,

294
00:20:00,280 --> 00:20:05,420
아니면 이런것들을 공통 비지니스 모델로 통합하고 공통 접근 패턴을 사용하는 것이 좋은지에 대한 것이었습니다.

295
00:20:05,520 --> 00:20:08,160
이게 저희가 했던 격렬한 논쟁의 내용이었어요

296
00:20:08,800 --> 00:20:10,800
이 부분에서의 어려운점은

297
00:20:11,160 --> 00:20:16,140
다시 새로운 형태의 모놀리틱 형태가 발생할 수 있다는 것입니다.

298
00:20:16,380 --> 00:20:20,780
여기 수백개의 서비스와 연결을 담당하는 API 게이트웨이가 있는데요

299
00:20:20,780 --> 00:20:24,620
이 게이트웨이 프로세서 안에 엄청나게 많은 코드가 동작하게 되었습니다.

300
00:20:24,860 --> 00:20:30,180
이건 2000년대 초반까지 사용했던 모놀로틱처럼 거대한 코드 베이스가 되어 버렸습니다.

301
00:20:32,220 --> 00:20:35,740
이런 모습은 기생충 감염 상태와 매우 유사합니다.

302
00:20:35,920 --> 00:20:40,300
이건 무슨 고질라 같은 거대 괴물이 도쿄를 파괴하는 그런 것이 아니라

303
00:20:40,840 --> 00:20:43,200
장기에 서식 하면서

304
00:20:43,200 --> 00:20:44,740
혈관에 딱 붙어

305
00:20:44,740 --> 00:20:46,600
드라큐라 같이 피를 먹고 사는 것이죠

306
00:20:46,600 --> 00:20:48,080
보시는 것은 십이지장충 입니다

307
00:20:48,180 --> 00:20:51,920
이게 다 자라난 상태가 되면 숙주는 빈혈 증상을 겪게 되구요

308
00:20:51,920 --> 00:20:53,100
약해지게 만들죠

309
00:20:53,100 --> 00:20:55,040
똑같이

310
00:20:55,180 --> 00:21:01,020
아무 지식 없이 사용하는 클라이언트 라이브러리는 여러분의 서비스를 비슷한 방식으로 약하게 만들 수 있습니다.

311
00:21:01,200 --> 00:21:03,420
여러분이 예상했던 것 이상의 heap을 사용하거나

312
00:21:03,560 --> 00:21:07,100
애플리케이션 안에서 논리적 오류를 일으킬 수도 있으며

313
00:21:07,420 --> 00:21:13,760
다른 의존성이 있는 라이브러리와 충돌하여 빌드가 깨지거나 하는 등의 문제 입니다.

314
00:21:13,760 --> 00:21:15,440
이게 실제로 일어 났던 현상인데요

315
00:21:15,440 --> 00:21:20,540
API 팀에서 먼저 생겼는데, 바로 이 부분이 수많은 팀에서 만든 수많은 라이브러리를 사용해야 했기 때문입니다.

316
00:21:21,620 --> 00:21:23,920
여기에 확실한 해답은 없습니다.

317
00:21:26,100 --> 00:21:28,100
수많은 논의들이 있지만

318
00:21:28,160 --> 00:21:31,240
아직까지는 어떤 결론이 나지는 않았습니다.

319
00:21:31,420 --> 00:21:35,760
지금까지 나온 방법으로는, 이런 라이브러리를 더 간단하게 만드는 것입니다.

320
00:21:35,820 --> 00:21:39,640
모든 요청을 베어-본 REST 모델로 만들 필요는 없지만

321
00:21:40,060 --> 00:21:44,420
로직의 규모나 heap 사용등을 제한할 필요는 있습니다.

322
00:21:44,500 --> 00:21:49,720
그리고 이걸 사용하는 사람들이 각 사용사례 별로 올바르게 사용할 수 있어야 합니다.

323
00:21:50,000 --> 00:21:53,280
아직 논의중인 문제라 결론이 난 것은 아니지만,

324
00:21:53,300 --> 00:21:58,060
이걸 설명드린 이유는, 어떤 상황에 어떤 것을 선택해야 하는지에 대한 이해를 공유하기 위함입니다.

325
00:21:59,820 --> 00:22:06,120
제생각에 넷플릭스가 초반부터 적절하게 접근한 부분이 바로 데이터 저장인데요, 어떻게 잘못했는지 같은 전쟁사는 없습니다

326
00:22:06,240 --> 00:22:08,840
올바른 구현을 어떻게 했는지 말해드릴께요

327
00:22:09,540 --> 00:22:14,540
시작은 CAP 이론을 어떻게 올바르게 구현할 것인가 였습니다

328
00:22:15,000 --> 00:22:18,840
혹시 CAP 이론을 처음 들어보시는 분 계신가요

329
00:22:18,860 --> 00:22:20,860
아 많지 않네요

330
00:22:21,080 --> 00:22:27,300
계속 진행하겠습니다. 공통적 이해를 위해, 제가 생각하는 CAP 이론을 정리해 봤는데요

331
00:22:27,500 --> 00:22:33,140
네트워크가 분리된 환경에서는 가용성과 일관성중 반드시 하나를 선택해야 한다는 것 입니다.

332
00:22:34,200 --> 00:22:37,200
여기 보시면 네트워크 A에서 동작하는 서비스가 있구요

333
00:22:37,360 --> 00:22:41,620
이 서비스는 동일한 데이터를 여러개의 데이터베이스에 각각 저장하려고 하는데,

334
00:22:41,820 --> 00:22:44,960
이 데이터베이스들은 서로 다른 네트워크에 존재 합니다.

335
00:22:44,960 --> 00:22:47,680
AWS 기준으로는 3개의 다른 AZ 입니다

336
00:22:48,320 --> 00:22:52,280
기초적인 질문은, 만약 한개 이상의 데이터베이스에 접근이 안되면 어떻게 할 것인가 입니다

337
00:22:52,600 --> 00:22:55,500
실패를 그대로 받아들이고, 에러를 리턴할 것인지

338
00:22:55,580 --> 00:22:59,300
일단 되는 곳에 먼저 저장하고, 나중에 정상화 되면 복제 할 것인지

339
00:23:00,400 --> 00:23:02,400
넷플릭스는 후자를 선택 했습니다

340
00:23:02,540 --> 00:23:05,640
'최종 일관성' 을 추구하는 형태였습니다

341
00:23:05,720 --> 00:23:11,800
데이터를 저장하고, 이 데이터에 대해 즉시 읽기를 수행하지 않는 것입니다

342
00:23:12,520 --> 00:23:15,260
카산드라는 이런 형태의 작업을 정말 훌륭하게 처리 합니다

343
00:23:15,520 --> 00:23:17,520
굉장히 유연하구요

344
00:23:17,740 --> 00:23:22,480
클라이언트가 하나의 노드에만 쓰기를 수행해도, 이 데이터를 모든 노드에 복제 합니다

345
00:23:23,080 --> 00:23:25,080
여기엔 "정족수" 컨셉이 있는데

346
00:23:25,180 --> 00:23:28,000
지정한 숫자 이상의 노드에서 변경에 대한 커밋이 있어야

347
00:23:28,120 --> 00:23:30,520
실제 데이터에 대한 변경이 적용되는 방법 입니다

348
00:23:30,680 --> 00:23:32,860
제가 데이터가 변경 됬다고 가정하는 대신 말이죠

349
00:23:32,920 --> 00:23:39,700
만약 매우 높은 가용성을 목적으로 내구성의 위험을 감수한다면 이 정족수를 1대의 노드로 적용할 수 있으며

350
00:23:39,780 --> 00:23:43,960
반대로 내구성을 높이기 위해서라면 모든 노드가 복제 된 후에 변경을 커밋할 수 있습니다.

351
00:23:46,220 --> 00:23:51,780
이제 오늘의 전체 주제인 인프라에 대한 이야기로 넘어가 보도록 하겠습니다

352
00:23:52,220 --> 00:23:54,220
언제 어떤 순간 에서든

353
00:23:54,440 --> 00:24:00,140
AWS건, 구글이건 여러분이 직접 구성한 인프라건 간에 장애는 발생합니다

354
00:24:00,560 --> 00:24:05,480
여기서의 포인트는 아마존이 서비스를 못한다는 것이 아니라, 사실은 매우 훌륭하죠

355
00:24:05,480 --> 00:24:07,640
모든건 고장날 수 있다는 겁니다

356
00:24:07,920 --> 00:24:13,960
2012년 크리스마스 이브에 발생한 장애에 대해 살펴보자면

357
00:24:14,060 --> 00:24:16,060
EOB 제어판이 다운 되었는데

358
00:24:16,200 --> 00:24:18,520
마치 제 가진 계란을 모두 한 바구니에 넣은 것처럼

359
00:24:18,640 --> 00:24:20,900
넷플릭스의 모든 리소스가 us-east-1 에 있었습니다

360
00:24:20,900 --> 00:24:22,760
us-east-1 에 장애가 발생하자

361
00:24:22,860 --> 00:24:26,560
아, 미리 언급하자면 여기에 대한 조사를 충분히 했구요

362
00:24:26,560 --> 00:24:28,500
어쨌든 해당 리전이 문제가 된 후 대안이 없었어요

363
00:24:29,060 --> 00:24:34,580
그래서 넷플릭스는 3개의 AWS 리전을 바탕으로 멀티 리전 전략을 구상했는데요

364
00:24:34,720 --> 00:24:40,620
어떤 리전이 완전히 동작하지 않는 경우에도 서비스에는 전혀 문제가 없습니다

365
00:24:43,220 --> 00:24:46,180
작년에 이 주제로 한번 이야기를 했었구요

366
00:24:46,380 --> 00:24:53,340
넷플릭스가 어떻게 멀티 리전을 구현했는지 궁금하시다면 살펴 보세요

367
00:24:53,600 --> 00:24:56,780
그러니 이 부분은 넘어 가도록 하겠습니다

368
00:24:57,560 --> 00:24:59,760
이제 확장성에 대해 이야기 해 봅시다

369
00:24:59,760 --> 00:25:02,420
확장성 부분에선 3개의 사례를 볼건데요

370
00:25:02,520 --> 00:25:04,600
stateless 서비스 시나리오,

371
00:25:04,700 --> 00:25:08,240
stateful 서비스 시나리오, 이 두가지가 기본이구요

372
00:25:08,440 --> 00:25:14,640
이전에 보셨던 모든 것들이 조합된 형태 같은 하이브리드 서비스 시나리오의 3가지 입니다

373
00:25:17,120 --> 00:25:21,480
자, 이제 다른 질문인데요, stateless 서비스란 무엇인가요?

374
00:25:23,240 --> 00:25:26,740
의견을 말해 주실분 계신가요?

375
00:25:28,380 --> 00:25:30,380
아, 저기 용감한 영혼이 나타나셨어요  좋습니다

376
00:25:30,900 --> 00:25:36,660
[누군가 답변 중]

377
00:25:36,960 --> 00:25:38,960
아, 흥미로운 답변이네요

378
00:25:39,500 --> 00:25:42,860
제 생각은, 이건 캐시나 데이터베이스 이야기가 아니죠

379
00:25:42,920 --> 00:25:45,220
엄청나게 많은 데이터를 저장할 필요가 없는 것입니다

380
00:25:45,540 --> 00:25:50,380
매우 자주 요청되는 메모리에 캐시된 메타데이터죠

381
00:25:50,520 --> 00:25:54,420
따라서 태생적으로 이건 휘발성이 있는 데이터라고 할 수 있죠

382
00:25:55,040 --> 00:26:02,620
고객이 동일한 서버에 접근하도록 해야 할 필요가 없는 경우도 해당 됩니다

383
00:26:03,380 --> 00:26:07,700
가장 중요한 컨셉은, 서버의 문제가 서비스의 문제는 아니라는 점입니다

384
00:26:07,700 --> 00:26:10,840
이게 잘못 되었다고 해서 시간을 엄청나게 써야 하는 그런 류의 일이 아닌거죠

385
00:26:10,860 --> 00:26:13,760
아주 빠르게 복구 할 수 있습니다

386
00:26:13,760 --> 00:26:18,760
그저 동일한 역할을 하는 서버를 새로 켜기만 하면 보통 해결되는 문제죠

387
00:26:19,660 --> 00:26:24,200
다시 의학으로 돌아가 보면, 이걸 구현하는 가장 좋은 방법은 바로 '복제' 입니다

388
00:26:24,500 --> 00:26:30,100
우리 몸의 세포가 연속적으로 어떤건 죽고, 어떤건 복제를 통해 새로 생겨나듯이 말이죠

389
00:26:30,860 --> 00:26:33,040
오토스케일링이 이런 부분을 담당합니다

390
00:26:33,200 --> 00:26:35,660
물론 많은 분들이 오토스케일링에 대해 잘 아시겠지만

391
00:26:35,740 --> 00:26:41,860
이게 클라우드 기반 마이크로 서비스에서 굉장히 중요하기 때문에 다시 한번 강조 하는걸로 이해해 주세요

392
00:26:42,100 --> 00:26:46,760
확장에 대한 최소 값과 최대 값이 있지요, 그리고 확장을 언제 할지에 대한 매트릭이 있습니다

393
00:26:46,840 --> 00:26:53,080
새로운 서버가 시작될때 S3로 부터 원본을 가져와서 구동 되는 형태입니다

394
00:26:54,280 --> 00:26:59,680
다양한 장점이 있는데요, 먼저 트래픽에 따라 서버를 켜고 끄니까 효율이 좋습니다

395
00:27:00,040 --> 00:27:02,040
고장난 서버를 쉽게 대체할 수 있구요

396
00:27:02,280 --> 00:27:08,740
가장 좋은 점은, DDoS나 급격한 요청의 증가로 인해 트래픽이 폭증하는 경우 또는 성능상의 버그가 있는 경우에도

397
00:27:09,120 --> 00:27:14,180
무슨일이 발생한건지 분석하는 동안, 서비스가 정상적으로 동작할 수 있도록 해 줍니다

398
00:27:14,360 --> 00:27:18,040
아주 강력하게 사용하시는걸 권고드리구요

399
00:27:18,280 --> 00:27:21,260
'카오스'를 만들어 내는 방법으로 이런 방법이 동작한다는걸 확인 합니다

400
00:27:21,320 --> 00:27:23,960
'카오스 몽키'는 거의 최초의 카오스 도구였구요

401
00:27:24,140 --> 00:27:29,420
이게 하는 일은 어떤 노드가 죽어도 서비스는 문제가 없다는것을 확인하는 겁니다

402
00:27:29,420 --> 00:27:35,280
넷플릭스에선 카오스 몽키를 도입한 후에, 오토스케일링이 잘 동작하는지 걱정하는 일은 없습니다

403
00:27:36,360 --> 00:27:38,840
이런 장애는 더 이상 문제가 아니었습니다

404
00:27:38,840 --> 00:27:43,100
stateless 로 동작하는 단일 노드의 장애는 사실 살펴볼 필요도 없는것이 되었죠

405
00:27:44,100 --> 00:27:50,060
stateless의 반대인 stateful 서비스에 대해 알아 봅시다

406
00:27:50,240 --> 00:27:53,020
네, 이건 데이터베이스와 캐시 입니다

407
00:27:53,180 --> 00:28:01,280
이건 가끔 엄청나게 많은 양의 데이터를 내부 캐시에 가지고 있는 커스텀 앱으로 구현 될 수도 있습니다. 넷플릭스는 그랬죠

408
00:28:01,460 --> 00:28:03,400
넷플릭스는 이것만을 위한 서비스 구간이 있었는데요

409
00:28:03,400 --> 00:28:07,500
멀티 리전 전략을 선택하면서 리전간 데이터를 복제할 필요가 있었는데요

410
00:28:07,500 --> 00:28:09,440
이 부분이 가장 골치였습니다

411
00:28:09,600 --> 00:28:16,400
그래서 저는 여러분이 가능하다면 비지니스 로직과 상태 데이터를 하나의 애플리케이션에 모두 저장하는 방법을 피하는걸 권고 드립니다

412
00:28:17,060 --> 00:28:22,800
stateless 와 가장 다른점은, 서버(노드)의 장애가 신경써야 하는 이벤트라는 것입니다

413
00:28:23,340 --> 00:28:27,260
이런 서버들은 기존의 서버를 준비하고 대체하는데 몇시간이 걸릴수도 있습니다

414
00:28:27,720 --> 00:28:30,060
그래서 더욱 더 조심해야 하는 부분이죠

415
00:28:30,840 --> 00:28:34,300
이 부분에 대해 살짝 비밀을 알려드리자면

416
00:28:34,340 --> 00:28:38,720
캐시 접근 방법에 대한 2가지를 강조하고 싶습니다

417
00:28:38,920 --> 00:28:42,400
이전에 말씀 드린것처럼, 넷플릭스에는 야후로 부터 이직한 많은 엔지니어가 있었는데요

418
00:28:42,440 --> 00:28:46,260
이분들은 HAproxy 와 Squid 캐시에 대한 경험이 많았습니다

419
00:28:46,460 --> 00:28:50,460
여기서의 패턴은 고객을 위해 할당된 노드가 있구요,

420
00:28:50,460 --> 00:28:53,060
따라서 특정 고객은 정해진 노드의 캐시에 언제나 접근하고

421
00:28:53,060 --> 00:28:55,320
따라서 데이터는 딱 하나만 저장 됩니다

422
00:28:56,280 --> 00:29:00,160
여기서의 문제는 당연히 해당 노드에 장애가 생기는 경우인데요

423
00:29:00,160 --> 00:29:03,580
장애가 난 서버의 고객들은 서비스에 접근이 불가능하겠죠

424
00:29:04,080 --> 00:29:09,140
더 큰 문제는, 그러니까 우리가 Hystrix 를 가지기 이전의 시절에서

425
00:29:09,300 --> 00:29:13,420
스레드 풀에 대해 격벽과 같은 방법으로 격리를 할 수 있는 방법이 없었다는 거죠

426
00:29:13,540 --> 00:29:17,460
아직도 기억나는 전화가 있는데, 1개의 노드가 다운 되면

427
00:29:17,520 --> 00:29:20,400
넷플릭스 전체에 장애가 발생 했습니다

428
00:29:20,520 --> 00:29:27,580
캐시에 다시 데이터를 올려서 서비스를 복구하는데 3.5 시간이 걸렸어요

429
00:29:28,460 --> 00:29:31,680
이게 바로 하지 말아야할 패턴이죠. 피해야 합니다

430
00:29:32,320 --> 00:29:34,320
다시 의학으로 돌아가 보면

431
00:29:34,520 --> 00:29:36,520
예비 리소스를 생각하는 것이 기본입니다

432
00:29:36,680 --> 00:29:39,240
우리 몸에는 두개의 신장이 있고 하나에 문제가 생기더라도

433
00:29:39,320 --> 00:29:41,840
다른 하나를 아직 사용할 수 있죠. 그리고 우린 2개의 폐가 있어요

434
00:29:42,240 --> 00:29:46,640
신장과 같죠. 이건 처리량을 올려줄 뿐만 아니라 하나만 동작하는 경우에도 생존은 가능합니다

435
00:29:47,120 --> 00:29:50,280
우리의 몸과 같이

436
00:29:50,340 --> 00:29:54,360
넷플릭스는 EVcache 라는 기술을 도입했습니다

437
00:29:54,500 --> 00:29:57,560
EVcache 는 기본적으로 memcached 를 랩핑한거구요

438
00:29:57,640 --> 00:30:00,280
Squid 캐시처럼 샤딩되어 있습니다

439
00:30:00,340 --> 00:30:03,060
다만 다른것은 데이터가 여러개의 노드에 중복해서 저장된다는 것이죠

440
00:30:03,060 --> 00:30:05,040
따라서 쓰기가 발생할 때마다

441
00:30:05,100 --> 00:30:07,220
여러개의 노드에 데이터가 저장되고

442
00:30:07,240 --> 00:30:10,020
이 저장되는 데이터는 여러개의 AZ로 복제 되어

443
00:30:10,020 --> 00:30:13,220
결과적으로 다수의 네트워크에 데이터가 존재하게 됩니다

444
00:30:13,740 --> 00:30:15,740
읽기를 할때도

445
00:30:15,860 --> 00:30:18,500
읽기는 효율을 위해 기본적으로 로컬 AZ에서 수행 되지만

446
00:30:18,680 --> 00:30:23,820
그렇지만 접근해야 할 노드가 로컬에 없는 경우엔 다른 AZ의 노드에서 데이터를 가져올 수 있죠

447
00:30:24,640 --> 00:30:27,840
이건 매우 성공적인 사례고, 많이 사용되고 있구요

448
00:30:27,920 --> 00:30:33,320
EVcache 는 캐시가 필요한 모든 서비스에서 사용되고 있습니다

449
00:30:33,500 --> 00:30:38,080
넷플릭스에서 이 캐시는 아주 유용한 도구였습니다

450
00:30:38,900 --> 00:30:41,700
이제 이 두가지 방법을 조합하는 것에 대해 생각해 봅시다

451
00:30:41,800 --> 00:30:46,100
하이브리드 서비스라 불리는 구조일 텐데요

452
00:30:47,640 --> 00:30:52,700
EVCache 를 별거 아닌것 처럼 생각하기 쉽습니다. 왜 인지 말씀 드릴게요

453
00:30:53,620 --> 00:30:58,240
EVCache는 글로벌에서 초당 3천만 요청을 처리 합니다

454
00:30:58,340 --> 00:31:00,720
이건 하루에 2조개의 요청에 해당하는 분량이구요

455
00:31:01,140 --> 00:31:04,180
이건 수천억개의 오브젝트를 저장하고 있으며

456
00:31:04,240 --> 00:31:07,360
수만개의 memcached 인스턴스를 사용합니다

457
00:31:07,460 --> 00:31:09,580
이게 가장 큰 장점인데요,

458
00:31:09,820 --> 00:31:15,540
요청의 숫자가 아무리 늘어나도 밀리세컨 단위의 응답 속도가 유지 됩니다

459
00:31:15,540 --> 00:31:19,660
적절한 수량의 노드가 동작한다면, 트래픽이 아무리 많아도 처리가 가능한 구조입니다

460
00:31:20,480 --> 00:31:23,640
몇년 전에 한가지 시나리오가 있는데요

461
00:31:23,640 --> 00:31:25,880
사용자 정보를 저장하는 서브스크라이버 서비스가

462
00:31:25,880 --> 00:31:28,340
EVCache 에 조금 많이 의존하고 있었는데,

463
00:31:28,340 --> 00:31:30,720
이것 역시 또 하나의 하면 안되는 패턴이죠

464
00:31:31,140 --> 00:31:35,720
그리고 이 사용자 정보를 필요로 하는 많은 서비스가 있었죠

465
00:31:35,720 --> 00:31:39,940
이를테면 사용자 id라던가, 사용자 정보에 필요한 그런것들 있잖아요

466
00:31:40,620 --> 00:31:45,700
이건 동일한 EVCache 클러스터를 통해 제공 되는, 온라인과 오프라인에서 모두 요청되는 서비스 였는데

467
00:31:45,720 --> 00:31:49,480
추천을 위한 배치 프로세스에서 사용자 정보를 가져가기 위해 호출하기도 하고

468
00:31:49,480 --> 00:31:51,420
여기에 실시간 데이터 호출도 있었죠

469
00:31:52,360 --> 00:31:58,920
이 경우, 하나의 요청 주기 안에서 동일한 애플리케이션에서 동일한 데이터에 대한 요청까지도 EVCache 로 유입 되었는데

470
00:31:59,020 --> 00:32:04,240
이건 사람들이 캐시를 원할때 언제든 호출하기가 쉬웠기 때문입니다

471
00:32:04,380 --> 00:32:10,820
이로 인해 피크 상태에서는 서비스에 대한 요청이 초당 80만에서 백만건 정도로 폭증하게 되었습니다

472
00:32:11,140 --> 00:32:14,920
일반적으로 fallback 의 방법은 한개만 문제가 되었을때는 잘 동작하지만

473
00:32:14,920 --> 00:32:18,440
예를 들어 캐시요청 하나가 미스가 나면 데이터베이스 서비스로 요청을 하고

474
00:32:18,480 --> 00:32:22,600
하지만 EVCache 계층이 완전히 다운되면 다른 이야기가 되는데

475
00:32:22,860 --> 00:32:26,860
이때도 데이터베이스 서비스로 호출을 수행하는 안티 패턴이 나타납니다

476
00:32:27,440 --> 00:32:32,100
기본적으로 데이터베이스 서비스는 EVCache 가 처리하던 요청을 처리할 능력이 되지 않습니다

477
00:32:32,120 --> 00:32:35,540
따라서 올바른 접근은, 실패를 빠르게 하는 것이었습니다

478
00:32:36,180 --> 00:32:39,600
엄청난 요청을 처리하던 EVCache 가 다운되면,

479
00:32:39,900 --> 00:32:42,340
전체 서브스크라이버 서비스의 다운으로 이어집니다

480
00:32:42,720 --> 00:32:44,720
몇가지 해법이 있는데

481
00:32:44,840 --> 00:32:50,460
첫번째는 배치 작업을 위한 캐시 요청과 실시간 캐시 요청을 분리하는 것이었습니다

482
00:32:51,820 --> 00:32:57,620
그리고 하나의 요청 안에서 발생하는 캐시 참조는 한번만 발생 하도록 함으로서

483
00:32:57,740 --> 00:33:02,300
처음 한번만 데이터 참조를 수행하는 방법을 적용 함으로서 하나의 요청에서 보다 효율적으로 리소스를 사용할 수 있었습니다

484
00:33:02,420 --> 00:33:04,420
그리고 아직 적용하진 않았지만

485
00:33:04,440 --> 00:33:06,580
이제 곧 적용할 것중 하나는

486
00:33:06,740 --> 00:33:11,640
클라이언트 장치에 서비스 접근에 필요한 보안 토큰을 저장함으로서

487
00:33:11,640 --> 00:33:13,960
만약 서브크스라이버 서비스가 다운된 경우

488
00:33:14,140 --> 00:33:17,500
암호화된 토큰을 이 장치에 저장된 것으로 사용하는 방법입니다

489
00:33:17,500 --> 00:33:20,280
이 토큰에는 사용자를 인증하기 위해 필요하기에 충분한 데이터가 저장되어 있어야 하며

490
00:33:20,320 --> 00:33:26,580
사용자가 서비스를 지속적으로 사용할 수 있도록 하는 사용자 경험을 제공할 수 있습니다

491
00:33:27,900 --> 00:33:32,860
그리고 카오스 도구들을 사용해서 부하를 시뮬레이션 합니다

492
00:33:33,760 --> 00:33:38,640
이제 다양성으로 넘어가 봅시다. 이건 다양한 아키텍처가 서비스 내에 존재하는 것을 의미 합니다

493
00:33:38,680 --> 00:33:45,440
서비스에 다양한 아키텍처가 존재한다는 것은 바로 복잡성이 증가한다는 것이며, 이건 서비스의 관리를 힘들게 하는 요인입니다

494
00:33:45,980 --> 00:33:48,280
두개의 사례를 공유할텐데요

495
00:33:48,280 --> 00:33:51,520
하나는 시간이 흐르면서 발생하는 오퍼레이션의 변화 이고

496
00:33:51,660 --> 00:33:59,100
다른 하나는 작년에 저희가 발표한 새로운 언어와 컨테이너를 아키텍처에 도입한 것입니다.

497
00:34:00,680 --> 00:34:03,240
운영의 변화는 강제로 발생하는 것이 아닙니다

498
00:34:03,560 --> 00:34:06,900
어떤 목적에 의해 자연스럽게 변화 됩니다

499
00:34:08,520 --> 00:34:15,120
시간이 흐르면서 발생하는 것들은, 알람의 임계점을 설정하고 유지하는 것 입니다

500
00:34:15,460 --> 00:34:20,880
배치 작업의 시간이 점점 길어지거나 하는 등의 이유로 타임 아웃과 같은 설정을 변경해야 할 필요가 있을겁니다

501
00:34:21,540 --> 00:34:28,300
처리 성능 역시 지속적으로 테스트를 통해 확인하지 않으면 새로운 기능을 추가하는 등의 영향으로 약간씩 느려질 수도 있습니다

502
00:34:28,780 --> 00:34:32,040
그리고 여러개의 마이크로 서비스에서도

503
00:34:32,040 --> 00:34:34,940
서비스를 운영하고 유지하는 방법에 굉장히 좋은 패턴을 발견했어도

504
00:34:34,960 --> 00:34:38,320
팀의 절반의 엔지니어만이 이 패턴을 구현 가능한 경우도 있습니다

505
00:34:39,920 --> 00:34:42,260
처음 어떤 팀에 가서

506
00:34:42,260 --> 00:34:46,840
"이 문제를 해결해 보자!", "알람을 좀 튜닝해 보자!", "부하 테스트를 해 보자!",

507
00:34:46,920 --> 00:34:51,820
"서비스 성능을 개선하고 가용성을 높이는 튜닝을 해 보자!" 하고 말하면

508
00:34:52,000 --> 00:34:56,140
그 팀으로 부터 처음엔 아주 긍정적인 반응을 볼 수 있을 겁니다

509
00:34:56,460 --> 00:35:00,760
하지만 사람은 이런 수작업을 반복적으로 하는데 별로 뛰어나지 않죠

510
00:35:00,880 --> 00:35:03,360
그래서 사람들은 다른일을 하고 싶어할거에요

511
00:35:03,360 --> 00:35:08,820
제품을 만드는 본연의 일에 집중하거나, 다음번 A/B 테스트를 준비하거나 하는 것들 말이죠

512
00:35:08,820 --> 00:35:10,700
그리고 그 다음번에 그 팀에 가서

513
00:35:10,960 --> 00:35:16,200
같은 방식으로 말을 하면, 아마도 그 전보다는 덜 긍정적인 반응을 보일 겁니다.

514
00:35:17,760 --> 00:35:24,720
앞에서와 같이 의학 부문에서 지율 신경계의 사례를 다시 참고해 보면,

515
00:35:24,940 --> 00:35:29,320
여러분이 생각하지 않아도 자연스럽게 몸이 알아서 하는 기능들이 있습니다

516
00:35:29,760 --> 00:35:32,140
여러분은 소화에 대해 생각할 필요가 없죠

517
00:35:32,140 --> 00:35:35,440
숨쉬는 것도 생각할 필요가 없어요. 안그러면 잠들면 죽겠죠

518
00:35:36,060 --> 00:35:43,100
이와 동일한 방식으로 마치 잠재 의식이 동작하듯이 환경을 설정할 필요가 있는데요

519
00:35:43,260 --> 00:35:47,940
사람들이 수동으로 처리하거나, 굳이 생각하지 않아도 알아서 동작하게 하는 것이죠

520
00:35:48,100 --> 00:35:53,820
넷플릭스는 지속적으로 학습하는 내용을 자동화하는 방식을 도입 했습니다

521
00:35:54,000 --> 00:35:57,100
보통은 사고를 통해 무언가를 학습 합니다

522
00:35:57,100 --> 00:35:59,060
어떤 장애가 발생하면

523
00:35:59,320 --> 00:36:03,100
엔지니어들은 콜을 하고, 이를 통해 고객의 문제를 해결 하고자 합니다

524
00:36:03,840 --> 00:36:07,080
사건에 대한 리뷰를 통해 서비스에 무슨 장애가 발생한건지 파악하고

525
00:36:07,100 --> 00:36:11,840
즉시 효과를 볼 수 있는 해결책을 강구해서 적용합니다

526
00:36:12,500 --> 00:36:14,500
이후에는 분석을 시작합니다

527
00:36:14,500 --> 00:36:15,960
이건 새로운 형태의 장애인가?

528
00:36:17,040 --> 00:36:19,680
이걸 해결할 수 있는 최적의 방법이 있는가?

529
00:36:19,680 --> 00:36:24,180
또는 서비스에 큰 영향을 미칠 수도 있는 반복적으로 발생하는 문제인가?

530
00:36:24,960 --> 00:36:28,540
그런것들을 알고나면, 가능한 모든 부분에 자동화를 시도합니다

531
00:36:28,960 --> 00:36:32,860
그리고 만들어진 자동화를 서비스에 반영하죠

532
00:36:32,860 --> 00:36:37,900
이게 바로 학습이 자동화 된 코드로 만들어지고, 마이크로 서비스에 반영되는 과정 입니다

533
00:36:39,680 --> 00:36:44,140
수년동안의 경험을 바탕으로 넷플릭스는 "프로덕션 수준으로 준비된" 것을 검증하는 방법이 축적되었는데

534
00:36:44,140 --> 00:36:47,240
이건 넷플릭스 고유의 프로그램이나 체크리스트들 입니다

535
00:36:47,460 --> 00:36:51,940
여기 나열된 부분은  그 뒤에 자동화 되어 동작하는 것들이며

536
00:36:51,940 --> 00:36:55,560
더 좋은 서비스를 만들기 위해 지속적으로 개선하는 것들 입니다

537
00:36:55,660 --> 00:36:59,400
더 나은 오토스케일링을 위해 알람을 손보거나,

538
00:36:59,400 --> 00:37:02,620
Stateless 서비스 검증을 위해 카오스 몽키를 사용하거나

539
00:37:02,620 --> 00:37:05,900
red-black 푸시의 방법을 사용해서 문제가 생길때 롤백을 할 수 있도록 만들거나

540
00:37:06,180 --> 00:37:08,120
가장 중요한 것 중 하나는

541
00:37:08,120 --> 00:37:12,960
배포를 스테이징에 먼저 적용함으로서 나쁜 코드를 전체 리전에 동시에 적용되지 않도록 하는 것입니다

542
00:37:14,900 --> 00:37:16,900
당연히 이 모든것들은 자동화 되어 있구요

543
00:37:18,620 --> 00:37:22,540
이제 다음 주제로 넘어가서 '폴리 글럿'과 '컨테이너'에 대해 말해볼겁니다

544
00:37:22,540 --> 00:37:25,140
이 두가지 모두 최근 몇년동안에 나타난 주제들이죠

545
00:37:25,140 --> 00:37:27,140
이것들은 변화가 적용되는 극단적인 모습인데요

546
00:37:27,140 --> 00:37:32,760
사람들은 마이크로 서비스에 이 새로운 기술들을 적용하고자 합니다

547
00:37:34,340 --> 00:37:38,500
3년전 제가 처음 운영 기술팀을 맡게 되었을때

548
00:37:38,520 --> 00:37:41,340
당시에 잘 동작하는 기술들은 이런 것들이었습니다

549
00:37:41,580 --> 00:37:46,260
이것들은 모두 넷플릭스에서 아주 잘 작동하는 도구들이었구요

550
00:37:46,280 --> 00:37:49,420
말씀 드렸던 자동화와 끊임없은 개선이 적용된 도구이자

551
00:37:49,460 --> 00:37:56,480
개발자들은 이 잘 구성된 도구 위에서 빠르게 서비스를 개발함으로서, 매우 효율적인 경험을 할 수 있었습니다

552
00:37:56,740 --> 00:37:58,740
자바에 집중 했구요

553
00:37:58,860 --> 00:38:02,560
약간의 반어법을 적용하면, EC2를 쌩으로 사용했는데

554
00:38:02,660 --> 00:38:06,860
EC2는 컨테이너와는 반대되는 것이거든요

555
00:38:07,940 --> 00:38:12,420
자바 기반의 아주 잘 동작하는 도구들 덕분에 스스로 자랑스러워 하는 동안

556
00:38:12,720 --> 00:38:16,620
다른 팀의 내부의 엔지니어 고객들은 오프로드를 달리기 시작했습니다

557
00:38:16,760 --> 00:38:18,760
자신들 만의 길을 걷기 시작한거죠

558
00:38:19,000 --> 00:38:24,460
오퍼레이션 작업에 완벽한 핏을 자랑하는 파이썬을 사용하기 시작했습니다

559
00:38:24,460 --> 00:38:27,320
그리고 루비로 만들어진 일부 백오피스 애플리케이션이 있었습니다

560
00:38:28,580 --> 00:38:36,160
그리고 웹 팀에서 와서 말하길, '우린 JVM 기반의 애플리케이션을 모두 NodeJS로 다시 개발할거에요' 라고 했습니다

561
00:38:36,300 --> 00:38:38,300
아주 흥미로운 기술이죠

562
00:38:38,600 --> 00:38:40,600
그리고 docker를 추가했구요

563
00:38:40,740 --> 00:38:42,740
점점 더 복잡해지기 시작했습니다

564
00:38:43,200 --> 00:38:48,620
이런 다양한 도구와 기술을 사용하는 것은 합리적이며 올바른 선택이었지만

565
00:38:48,620 --> 00:38:50,400
하지만

566
00:38:50,480 --> 00:38:55,800
이런 기술들을 서비스의 핵심 부분에 적용하는 것이 현실화하는데 어려움이 있긴 했지만

567
00:38:56,400 --> 00:38:59,520
이렇게 하는건 결과적으로 매우 타당했는데, 왜인지 말씀 드릴게요

568
00:39:00,860 --> 00:39:08,440
우리의 API 게이트웨이는 UI팀의 엔드 포인트로 동작하는 groovy 스크립트와 연동하는 기능이 있었는데

569
00:39:08,740 --> 00:39:11,160
모든 스크립트에 버저닝을 적용해서

570
00:39:11,400 --> 00:39:15,080
각각 변경이 발생할 때마다 프로덕션에 적용할 수 있었고

571
00:39:15,160 --> 00:39:21,960
필드에서 동작하는 각각의 장치와 싱크를 수행해서 업데이트된  엔드포인트 정보를 바탕으로 API 게이트웨이와 연동하는 방식이었습니다

572
00:39:22,380 --> 00:39:25,120
근데 이게 바로 또 다른 모놀리틱의 사례 입니다

573
00:39:25,440 --> 00:39:27,920
프로세스 안에서 동작하는 수많은 코드들,

574
00:39:28,080 --> 00:39:32,480
사람들은 이 서비스에 대한 다른 이해를 바탕으로 수많은 라이브러리를 사용했죠

575
00:39:32,680 --> 00:39:35,640
결국 엔드포인트가 지워지는 일이 발생하거나

576
00:39:36,080 --> 00:39:40,900
특정 스크립트에 서로 다른 버전이 너무 많이 생성되거나

577
00:39:40,900 --> 00:39:44,320
API 서비스가 가진 모든 메모리를 잡아먹는 문제도 있었습니다

578
00:39:44,420 --> 00:39:47,940
다시 말하지만, 피해야할 모놀리틱 패턴입니다

579
00:39:47,940 --> 00:39:49,900
논리적인 해법은

580
00:39:50,000 --> 00:39:54,300
각각의 엔드포인트를 API 서비스 바깥으로 꺼내는 작업이었고

581
00:39:54,740 --> 00:40:02,400
우리는 아주 작은 nodejs 앱을 docker 안에 넣어 분리하는 방식으로 구현 했습니다.

582
00:40:03,540 --> 00:40:08,900
이로 인해 API 서비스에 호출을 하는 다른 작은 서비스들로 나눌수 있었고, 문제를 해결 할 수 있었습니다

583
00:40:09,160 --> 00:40:15,020
여기에 NodeJS 애플리케이션을 사용함으로서 먼저 말씀드린 문제로 인한 장애를 고립할 수 있게 된거죠

584
00:40:16,400 --> 00:40:21,140
여기서 생각해야 할 것은, 이런 다양성을 유지하기 위한 비용 이 절대 공짜가 아니라는 점 입니다.

585
00:40:21,140 --> 00:40:24,720
사실 굉장한 비용이 드는 작업이기 때문에 반드시 생각해 볼 필요가 있습니다

586
00:40:25,680 --> 00:40:31,700
UI팀이 사용했던 groovy 스크립트 모델은 개발에 있어서 상당한 효율을 제공 했습니다

587
00:40:31,700 --> 00:40:36,760
인프라에 신경쓰는 대신 필요한 코드를 만드는데 집중할 수 있었죠

588
00:40:37,040 --> 00:40:44,840
그리고 이런 경험을  nodejs와 docker 컨테이너 모델을 도입하기 위해서 엄청난 일을 해야 했습니다.

589
00:40:45,960 --> 00:40:49,380
컨테이너에 어떤일이 발생하는지, 그리고 문제가 된 컨테이너를 서비스에서 제외하는 등의 작업을 위해서

590
00:40:49,380 --> 00:40:52,860
CPU와 메모리가 얼마나 사용되는지를 알기 위해서는

591
00:40:52,860 --> 00:40:57,880
기존과는 다른 도구와 다른 지표들을 필요로 했습니다.

592
00:40:58,640 --> 00:41:03,220
넷플릭스는 거의 대부분의 애플리케이션에  아주 기본적인 AMi를 사용했는데,

593
00:41:03,220 --> 00:41:06,500
지금은 특화된 더 많은 종류의 AMI가 존재 합니다

594
00:41:07,700 --> 00:41:09,700
노드 관리는 엄청난 비용이 들어요

595
00:41:09,860 --> 00:41:18,600
오늘날 우리가 클라우드 환경에서 원하는 방향으로 사용할 수 있는 아키텍처나 기술을 제공하고 있지  않기 때문이죠

596
00:41:18,840 --> 00:41:22,320
그래서 우린 Titus 라고 불리는 새로운 계층을 만들어야 했구요

597
00:41:22,400 --> 00:41:29,020
이건 Node가 동작하는 컨테이너의 오토스케일링을 비롯한 노드 교체등의 작업 관리를 처리하는 계층이며,

598
00:41:29,020 --> 00:41:32,220
이걸 만들기 위해 넷플릭스는 엄청난 비용을 투자해야 했습니다.

599
00:41:32,620 --> 00:41:36,980
그리고 우리가 수년동안 사용했던 JVM기반의 플랫폼 코드들은

600
00:41:37,120 --> 00:41:40,440
여러가지의 서비스사용을 편리하게 해주던 것들이죠

601
00:41:40,600 --> 00:41:44,300
이런 도구들을 다른 언어로도 동일하게 만들어야 하는지 아닌지의 결정과,

602
00:41:44,300 --> 00:41:49,220
Node를 사용하는 팀이 알아서 REST 호출이나 관리도구 같은것들을 직접 구현하게 할지

603
00:41:49,620 --> 00:41:57,180
이런 것들이 논의되고 절충되고 있는데, 예를 들면 플랫폼이 제공하는 일부 기능을 node 용으로 만든다던가 하는 것입니다

604
00:41:57,880 --> 00:42:01,120
그리고 매번 새로운 기술을 프로덕션에 반영할 때마다,

605
00:42:01,120 --> 00:42:03,040
예를 들면 클라우드로 서비스를 옮긴다던가,

606
00:42:03,040 --> 00:42:05,200
아키텍처에 큰 변화를 준다거나

607
00:42:05,320 --> 00:42:10,580
새로운 방법으로 기존의 것을 부수고 다시 만들어야 하는 작업을 해야 합니다.

608
00:42:10,920 --> 00:42:14,520
따라서 경험이 쌓여 익숙해 지려면 시간이 필요할 겁니다

609
00:42:15,700 --> 00:42:20,260
그래서 예전에는 하나의 포장도로만 있던 것이 여러 종류의 포장도로로 발전하게 되었고

610
00:42:20,460 --> 00:42:27,940
이런건 중앙화된 관리 및 지원을 제공하려는 팀에서는 매우 큰 도전이 되었습니다.

611
00:42:28,040 --> 00:42:30,520
이런 문제로 인해 저희는 최근 엄청난 토론을 진행했구요

612
00:42:30,540 --> 00:42:32,540
우리가 취하기로한 결론은

613
00:42:32,720 --> 00:42:41,420
비용 증가에 대해 인식을 바탕으로 엔지니어들이 아키텍처를 선택 할때 다양한 정보를 기반으로 올바른 선택을 하도록 돕는 것이었습니다.

614
00:42:42,220 --> 00:42:44,540
지원 범위를 제한하는데,  이를테면

615
00:42:44,600 --> 00:42:52,720
기본적으로는 JVM에 집중하되, node나 docker는 매우 필수적이기 때문에 지원을 확대하는 식 입니다

616
00:42:53,400 --> 00:43:00,060
그리고 논리적으로 예상되는 규모에 따른 우선순위를 설정하고 적절한 규모의 인력을 배치하며

617
00:43:00,160 --> 00:43:03,000
재사용 가능한 솔루션을 찾습니다.

618
00:43:03,180 --> 00:43:08,540
배포(딜리버리)의 경우 매우 일반적이기 때문에 다양한 언어를 지원하는데 별 문제가 없을것입니다

619
00:43:08,860 --> 00:43:10,860
하나의 예시 였구요

620
00:43:11,060 --> 00:43:16,500
또 다른 예는 아주 간단한 클라이언트 라이브러리를 자동으로 생성하는 것입니다

621
00:43:16,520 --> 00:43:19,820
자동으로 루비, 자바, 파이썬 버전을 생성해 내는 것이죠

622
00:43:20,040 --> 00:43:22,500
이런 공통적으로 사용할 수 있는 방법을 지속적으로 찾고 있으며

623
00:43:22,500 --> 00:43:26,460
여기에는 모든 경우에 들어맞는 하나의 해결법이 있는 것이 아니기 때문에

624
00:43:26,520 --> 00:43:31,000
이런 예시들이 각각의 처한 상황에 대한 판단을 하는데 도움이 되길 바랍니다

625
00:43:31,620 --> 00:43:34,660
이제 마지막 내용인 '변화'에 대해 이야기 해 보겠습니다

626
00:43:35,760 --> 00:43:37,760
지금 우리가 하는 건

627
00:43:37,940 --> 00:43:44,240
변화를 위해 무언가 바꾸고 부수고 새로 만드는 일을 "업무 시간에" 하는 겁니다.

628
00:43:44,240 --> 00:43:46,200
지금 보시는건 주중 장애 그래프인데요

629
00:43:46,200 --> 00:43:48,460
주말 보다 주중에 더 많도록 노력하는 중입니다

630
00:43:49,260 --> 00:43:51,520
그리고 이건 매우 흥미로운 시간별 장애 그래프인데요

631
00:43:51,520 --> 00:43:53,200
아침 9시에 뭔가 반영하고 "붐",

632
00:43:53,340 --> 00:43:56,200
바로 넷플릭스를 변화 시키고, 부술 시간인 겁니다.

633
00:43:56,200 --> 00:43:59,760
헤헤헤 우리는 이런일(변경으로 발생하는 장애)이 발생한다는거 다 알잖아요?

634
00:43:59,880 --> 00:44:01,960
그래서 이런 질문을 하게 됩니다.

635
00:44:02,000 --> 00:44:09,040
어떻게 가능한 빠르게, 그리고 뭔가를 부수지 않을 자신감을 가지고 변경을 적용할 수 있는가?

636
00:44:09,880 --> 00:44:14,020
여기에 대한 답변으로, 우린 새로운 딜리버리 플랫폼을 만들었습니다

637
00:44:14,100 --> 00:44:17,660
이건 저희가 오랜동안 사용했던 Asgard를 대체하구요

638
00:44:17,780 --> 00:44:20,940
이건 새로운 글로벌 클라우드 관리 플랫폼이구요

639
00:44:21,240 --> 00:44:24,060
자동화 된 배포를 수행하는 시스템 입니다

640
00:44:24,820 --> 00:44:26,820
이 부분이 아주 중요한데요

641
00:44:26,960 --> 00:44:39,340
Spinnaker는경험을 바탕으로 만들어진 자동화된 부분들을 프로덕션에 적절히 배포할 수 있도록 디자인된 도구 입니다.

642
00:44:39,660 --> 00:44:43,420
지금 보시는 파이프라인에는 2가지를 볼 수 있는데

643
00:44:43,420 --> 00:44:45,200
하나는 자동화된 카나리 분석인데,

644
00:44:45,200 --> 00:44:50,760
새로운 버전의 애플리케이션이 배포될때 자동으로 라이브 시스템에서 유입되는 트래픽의 일부를 새 버전으로 흐르게 하는 것이구요

645
00:44:51,080 --> 00:44:55,520
이를 통해 기존의 코드와 새로운 코드 중에 어떤게 나은지를 밝혀낼 수 있습니다.

646
00:44:55,580 --> 00:44:57,580
다른 하나는 스테이징 배포 입니다

647
00:44:57,580 --> 00:44:59,440
우리가 확실히 하고 싶었던건,

648
00:44:59,600 --> 00:45:01,660
아, 5분 남았다는 군요

649
00:45:01,740 --> 00:45:04,840
우리는 하나의 배포를 하나의 리전에만 수행하고 싶었는데요

650
00:45:04,840 --> 00:45:08,020
뭔가 크게 고장나더라도 다른 리전들로 트래픽을 분배할 수 있기 때문이죠

651
00:45:08,260 --> 00:45:11,200
그 외에도 보시는 것처럼 많은 기능이 있습니다

652
00:45:11,460 --> 00:45:18,360
장기적 관점에서 이전에 이야기 했던 "프로덕션 배포 확인 리스트"와 같이 다양성을 반영하기 위한 도구들은

653
00:45:18,360 --> 00:45:21,100
모두 배포 파이프라인에 언젠가는 반영 되어야 합니다

654
00:45:22,200 --> 00:45:26,080
시간이 얼마 없으므로 치트를 좀 쓸게요

655
00:45:26,480 --> 00:45:30,520
작년 (2016)에 리인벤트에서 발표를 한게 있는데요

656
00:45:30,520 --> 00:45:34,620
이런 기능들이 어떻게 서로 긴밀하게 엮여서 동작하는지에 대한 것입니다.

657
00:45:34,660 --> 00:45:42,200
프로덕션 레디, 성능 개선, 카오스 적용, Spinnaker 연동, 시스템 모니터링 등등에 대한 것이죠

658
00:45:42,200 --> 00:45:43,860
한번 보시는걸 추천 드립니다

659
00:45:44,420 --> 00:45:49,460
자 이제 마지막으로, 조직과 아키텍처에 대해 짧게 이야기 하도록 할께요

660
00:45:51,440 --> 00:45:54,960
아주 오래전에 "일레트릭 딜리버리"라 불리는 팀이 있었습니다

661
00:45:54,960 --> 00:45:59,480
"스트리밍"이라는 단어가 없을때 스트리밍을 했던 서비스 이름이에요

662
00:45:59,840 --> 00:46:04,180
실제로는 하드 드라이브와 같은 장치로  다운로드를 제공하는 거였죠

663
00:46:04,380 --> 00:46:08,740
초기의 고객 장치에서 동작하는 넷플릭스는 이런 모양이었습니다

664
00:46:08,820 --> 00:46:12,560
네트워킹과 같은 기본 기능을 포함하고

665
00:46:12,600 --> 00:46:15,940
보안과 등록, 재생을 하는 기능,

666
00:46:16,100 --> 00:46:18,100
그리고 사용자 인터페이스로 구성됬죠

667
00:46:18,140 --> 00:46:21,440
사용자 인터페이스는 당시에 아주 간단했는데요

668
00:46:21,760 --> 00:46:27,460
웹 사이트에서 원하는 영화를 선택하면 "큐 리더" 라는 도구에 등록되고, 장치를 켜면 영화가 재생되는 방식이었죠

669
00:46:28,440 --> 00:46:31,780
하나의 조직에서 개발할때는 잘 동작했습니다

670
00:46:31,940 --> 00:46:36,620
"일레트릭 딜리버리"라고 불리는 기능은 서버와 클라이언트 모두 하나의 조직에서 일했기 때문에

671
00:46:36,620 --> 00:46:40,320
매우 긴밀하게 협조하면서 업무를 수행 했습니다.

672
00:46:40,420 --> 00:46:45,500
시스템의 디자인은 XML 기반이었구요

673
00:46:45,740 --> 00:46:49,540
XML안에 독자적으로 만들어진 응답을 제공했으며,

674
00:46:49,720 --> 00:46:53,740
펌웨어를 버전별로 릴리즈 했는데, 배포 주기가 꽤 길었었죠

675
00:46:54,320 --> 00:46:57,600
이후에는 넷플릭스 API가 만들어 졌는데

676
00:46:57,680 --> 00:47:04,000
DVD사업과 관련된 외부 애플리케이션이 더 많이 넷플릭스에 접근하도록 만들거나

677
00:47:04,000 --> 00:47:08,380
우리는 이 부분에서 큰 성공을 거두었으면 하는 마음으로, 1000개의 꽃이 만발하게 하자! 라고 이야기 했었습니다.

678
00:47:08,560 --> 00:47:13,380
넷플릭스에 엄청난 가치를 주지는 못했기 때문에 사실 그다지 성공하지는 못했지만,

679
00:47:13,560 --> 00:47:18,680
당시 만든 넷플릭스 API는 넷플릭스 UI를 혁신하는 촉매가 되었습니다.

680
00:47:19,360 --> 00:47:21,360
이건 컨텐츠에 대한 메타데이터를 가지고 있었는데

681
00:47:21,460 --> 00:47:24,620
이건 서비스되고 있는 영화의 리스트를 생성하거나

682
00:47:25,180 --> 00:47:27,720
일반화된 REST API,

683
00:47:27,720 --> 00:47:29,420
JSON 스키마,

684
00:47:29,760 --> 00:47:33,600
HTTP 응답 코드 기반, 여기서 이야기 하는 것들은 대부분 현대의 아키텍처들이죠?

685
00:47:34,120 --> 00:47:39,920
그리고 외부 인증을 지원하기 위한 OAuth 보안 모델이 제공 되었습니다

686
00:47:39,920 --> 00:47:44,120
근데 클라이언트 장치 측면에서 발생했던 문제는

687
00:47:44,600 --> 00:47:47,060
이 두개의 계층에 대한 분리가 발생했다는 점입니다.

688
00:47:47,060 --> 00:47:51,120
2개의 완전히 다른 형태로 구성된 엣지 서비스가 생겼고

689
00:47:51,140 --> 00:47:54,220
하나는 REST, JSON, OAuth,

690
00:47:54,300 --> 00:47:59,240
다른 하나는 RPC, XML, 그리고 토큰 지원을 위한 커스텀 보안 모델의 서비스 였습니다

691
00:47:59,900 --> 00:48:06,520
그리고 이 두개의 팀 사이에는 방화벽이 있었는데 새로운 API 서비스는 기존의 NCCP보다 확장도 잘 안되고 했기 때문에

692
00:48:06,560 --> 00:48:11,100
API 서비스로 인해 발생한 문제가 NCCP 팀에 전화가 가는 등으로 인해

693
00:48:11,100 --> 00:48:14,260
필연적으로 서비스를 운용하는데 마찰이 발생했습니다.

694
00:48:14,600 --> 00:48:19,080
이 두개의 완전히 다른 서비스, 프로토콜, 스키마, 보안 모델은

695
00:48:19,100 --> 00:48:26,240
제가 이 두개 서비스를 완벽히 지원하는 클라이언트를 개발해야하는 개발자가 아님에 신께 감사해야할 정도였죠

696
00:48:26,420 --> 00:48:30,180
몇가지 기능때문에 두가지 서비스 모두 필요했는데, 예를 들면

697
00:48:30,180 --> 00:48:35,560
영화의 리스트에 재생 시간을 제한하는 라이센스를 포함해서 사용자 인터페이스로 전달하고

698
00:48:35,640 --> 00:48:42,760
그래서 리스트된 영화중 하나를 클릭하면 즉시 동영상이 재생되야 했지만, 이와 반대로 DRM을 위한 또 다른 호출이 필요 했습니다.

699
00:48:43,600 --> 00:48:50,500
이런 문제를 해결하기 위해 당시 넷플릭스에 근무하던 시니어 엔지니어에게 질문을 했습니다

700
00:48:50,760 --> 00:48:54,960
장기적 관점에서 어떤게 올바른 아키텍처일까?

701
00:48:55,620 --> 00:49:01,380
그 엔지니어의 이름은 피터였는데, 제 질문을 듣고 몇초 뒤에 되묻기를

702
00:49:01,380 --> 00:49:04,020
조직간의 문제도 함께 고려하고 있나요?

703
00:49:04,120 --> 00:49:07,860
만약 두 서비스를 합치거나 두 서비스를 쪼개면 조직에 무슨일이 생길까요?

704
00:49:09,180 --> 00:49:12,220
사실 이건 "콘웨이의 법칙"과 매우 깊은 관련이 있습니다

705
00:49:12,880 --> 00:49:16,640
혹시 들어보신 분, 하하, 누군가 웃으시는걸 들었는데요,

706
00:49:16,680 --> 00:49:19,440
웃으셨던분 "콘웨이의 법칙"에 대해 말해주실수 있나요?

707
00:49:20,320 --> 00:49:24,920
[누군가 답변중]

708
00:49:24,920 --> 00:49:26,340
아, 좋습니다

709
00:49:26,840 --> 00:49:31,020
여기 좀 더 구체적인 설명이 있는데요,

710
00:49:31,160 --> 00:49:37,960
"시스템은 시스템을 디자인하는 조직의 커뮤니케이션 구조를 반영 한다.", 아주 추상적이죠

711
00:49:37,960 --> 00:49:39,840
저거보다는 이게 좀 더 나은데요,

712
00:49:39,840 --> 00:49:43,480
"소프트웨어는 그걸 만든 조직의 구조를 닮는다."

713
00:49:43,820 --> 00:49:45,820
여기 제가 제일 좋아하는게 있네요

714
00:49:46,060 --> 00:49:50,160
컴파일러는 만드는 조직이 4개면 4개의 단계를 가지는 컴파일러가 만들어진다.

715
00:49:50,160 --> 00:49:51,520
[큰 웃음]

716
00:49:51,620 --> 00:49:53,620
네, 넷플릭스는 4단계의 컴파일러가 있습니다

717
00:49:53,620 --> 00:49:55,380
그랬었죠 ㅎㅎ

718
00:49:55,460 --> 00:49:58,640
이게 바로 꼬리에 흔들리는 개의 모습입니다.

719
00:49:58,940 --> 00:50:03,860
문제가 된 아키텍처는 해법이 우선시 된것이 아니라 아니라 조직을 우선했기 때문에 발생한 것입니다.

720
00:50:04,340 --> 00:50:09,360
앞서 말씀드린걸 보시면

721
00:50:09,500 --> 00:50:13,860
옛날 장치의 재생을 지원하기 위한 NCCP가 있구요

722
00:50:13,900 --> 00:50:15,400
그리고 새로운 API 서비스가 있습니다.

723
00:50:15,400 --> 00:50:16,720
엉망 진창이죠

724
00:50:16,880 --> 00:50:20,640
결과적으로 우리는 "블레이드 러너"라고 불리는 아키텍처를 적용했는데요

725
00:50:20,700 --> 00:50:22,700
왜냐면 우린 지금 "엣지" 서비스를 살펴보는 중이니까요

726
00:50:24,020 --> 00:50:36,820
NCCP의 기능은 결국 분리되어 Zuul 프락시 또는 API 게이트웨이, 그리고 다른 세분화된 아주 작은 새로운 마이크로 서비스들로 분화 되었는데,

727
00:50:36,960 --> 00:50:43,700
이들은 기본적인 보안 기능, 재생을 위주로한 기능 지원, 자막, 메타데이터 제공등의 역할을 합니다.

728
00:50:45,200 --> 00:50:47,200
저희가 배운건 이렇습니다

729
00:50:47,480 --> 00:50:55,160
두개의 서비스를 통합하는 방법은 넷플릭스에게 장기적으로 높은 수준의 성능과 개선 속도를 제공 함으로서

730
00:50:55,220 --> 00:50:58,600
더 강력한 클라이언트 개발에 집중할 수 있었기 때문입니다.

731
00:50:58,880 --> 00:51:06,000
제가 관리하는 모든 조직을 결국 넷플릭스 API팀으로 병합하는 방식으로 조직의 리팩토링을 했고

732
00:51:06,020 --> 00:51:08,600
그 후에 다시 오퍼레이션 엔지니어링으로 옮겼습니다.

733
00:51:08,820 --> 00:51:11,480
이건 사업을 위한 올바른 행동이었죠

734
00:51:11,520 --> 00:51:15,240
배운것은, 해법을 먼저 찾고 팀은 그 다음이다

735
00:51:15,360 --> 00:51:18,280
그리고 조직의 변화를 두려워 하면 안된다 는 것입니다

736
00:51:18,300 --> 00:51:20,300
이제 전체 세션을 마무리 할건데요,

737
00:51:20,320 --> 00:51:22,920
시간은 다 썼지만 몇분 더 하도록 하겠습니다

738
00:51:23,300 --> 00:51:25,300
정리하는 것이니까요

739
00:51:25,560 --> 00:51:30,680
마이크로 서비스 아키텍처는 인간의 장기와 마찬가지로 복잡합니다.

740
00:51:30,820 --> 00:51:37,440
그리고 서비스는 지속적, 그리고 정기적으로 카오스 상태를 테스트함으로서 더 강력해 질 수 있습니다.

741
00:51:37,760 --> 00:51:42,700
의존성에 있어서, 서킷 브레이커와 fallback, 그리고 카오스 적용을 고려하세요

742
00:51:42,920 --> 00:51:46,320
클라이언트를 단순화 하고, 최종 일관성을 적용하구요

743
00:51:46,740 --> 00:51:48,740
멀티 리전 복구 전략을 고려하세요

744
00:51:49,640 --> 00:51:51,920
확장에 있어선, 오토 스케일링 꼭 쓰세요

745
00:51:52,000 --> 00:51:54,560
간단하지만 큰 장점이 있습니다

746
00:51:54,560 --> 00:51:56,340
단일 장애 포인트를 없애야 합니다

747
00:51:56,340 --> 00:51:58,260
업무를 분리해야 하구요

748
00:51:58,400 --> 00:52:02,420
요청의 캐싱에 대한 예처럼 실패에 기반해서 디자인 하세요

749
00:52:02,660 --> 00:52:07,840
부하상태에서 카오스를 만드는 기법을 통해 예상 동작을 확인 하세요

750
00:52:08,300 --> 00:52:13,480
변경 관리에 있어선, 가급적이면 최대한 자동화를 구현하시구요

751
00:52:14,120 --> 00:52:17,840
아키텍처 다양성을 구현하고 유지하는 비용에 대한 이해와,

752
00:52:17,860 --> 00:52:21,860
중앙에서 관리하는 지원 조직이 있다면 지원에 우선순위를 고려하구요

753
00:52:21,880 --> 00:52:26,160
서비스 영향도에 기반한 우선순위 설정은 더 효율적인 지원이 가능하도록 만들어 줄 겁니다.

754
00:52:26,360 --> 00:52:31,100
변화에 있어서는 자동화된 배포와 경험을 지속적으로 반영하도록 합시다

755
00:52:31,180 --> 00:52:34,700
다시한번, 해법이 먼저고, 팀이 나중입니다.

756
00:52:35,360 --> 00:52:40,140
지금까지 설명한 다양한 전략을 구현할 수 있는 넷플릭스 오픈소스들이 있구요

757
00:52:40,220 --> 00:52:44,660
처음 들어보시는 분이 있다면 한번 살펴보시구요

758
00:52:45,480 --> 00:52:47,480
넷플릭스 테크 블로그도 살펴 보시고

759
00:52:47,660 --> 00:52:52,120
여러가지 문제들을 어떻게 확장성 있게 처리 했는지,

760
00:52:52,240 --> 00:52:58,640
세션에서 보신 다이어그램의 비쥬얼 도구인 Vizceral 과 같은 오픈소스의 공개에 대한 소식도 있습니다.

761
00:52:59,720 --> 00:53:02,600
시간이 없어서 질문은 받지 못할것 같은데요

762
00:53:02,660 --> 00:53:06,340
혹시 질문을 받을 시간이 있나요, 아니면 끝내고 뒤에서 받을까요

763
00:53:06,440 --> 00:53:10,080
아, 제가 너무 시간을 썼네요. 들어주셔서 감사합니다!!!

764
00:53:10,300 --> 00:53:12,980
자막: 정윤진 
yjeong@pivotal.io

